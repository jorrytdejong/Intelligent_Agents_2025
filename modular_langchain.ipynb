{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "292ae775",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24b99805",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import START, END, StateGraph\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from IPython.display import Image, display\n",
    "from langgraph.graph import MessagesState\n",
    "from langchain_core.messages import SystemMessage\n",
    "from owlready2 import get_ontology\n",
    "from langchain_core.messages import AIMessage\n",
    "from langgraph.prebuilt import tools_condition\n",
    "from pathlib import Path\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from pydantic import BaseModel\n",
    "from typing import List, Optional\n",
    "\n",
    "from owlready2 import *\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a10593",
   "metadata": {},
   "source": [
    "setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c19acb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MockLLM:\n",
    "    def invoke(self, messages):\n",
    "        return \"mocked assistant response\"\n",
    "\n",
    "llm_with_tools = MockLLM()\n",
    "sys_msg = SystemMessage(content=\"You are a helpful assistant.\")\n",
    "onto = get_ontology(\"IA_ontology.owl\").load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4048319",
   "metadata": {},
   "source": [
    "Define Pydantic classes for input, inbetween and output states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4608cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputState(TypedDict):\n",
    "    story: str\n",
    "\n",
    "class InbetweenState(TypedDict):\n",
    "    story: str\n",
    "    chunks: list[str]\n",
    "    ontology_summary: str\n",
    "    extract: list[str]\n",
    "    conflicts: list[str]\n",
    "    rewritten_chunks: list[str]\n",
    "    re_verified_chunks: list[str]\n",
    "    evaluated_chunks: list[str]\n",
    "\n",
    "\n",
    "class OutputState(TypedDict):\n",
    "    revised_story: str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b235885e",
   "metadata": {},
   "source": [
    "Functions to make a summary of the ontology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "62a26e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use IA_ontology.owl\n",
    "onto = get_ontology(\"IA_ontology.owl\").load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9af02b45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== SUMMARY of http://IA.org/onto.owl# ===\n",
      "\n",
      "CLASSES:\n",
      "  Activity\n",
      "  Adult\n",
      "  Adventurous\n",
      "  Allergy\n",
      "  AvoidsSocialInteraction\n",
      "  AvoidsTasks\n",
      "  Baguette\n",
      "  Baker\n",
      "  Baking\n",
      "  Behavior\n",
      "  Bicycle\n",
      "  BicycleLane\n",
      "  BigCity\n",
      "  Boiling\n",
      "  Bus\n",
      "  BusStation\n",
      "  BusyCity\n",
      "  Cake\n",
      "  Cancer\n",
      "  Car\n",
      "  Carbohydrate\n",
      "  Cashier\n",
      "  CatchingFish\n",
      "  CharacterTrait\n",
      "  Chef\n",
      "  City\n",
      "  Classroom\n",
      "  Condition\n",
      "  CookedFood\n",
      "  CookingMethod\n",
      "  Croissant\n",
      "  CuttingBoard\n",
      "  Dairy\n",
      "  DairyAllergy\n",
      "  Deficiency\n",
      "  Dessert\n",
      "  Diabetes\n",
      "  Disease\n",
      "  Doctor\n",
      "  Education\n",
      "  EducationalResource\n",
      "  Electricity\n",
      "  ElectricityUtility\n",
      "  EnvironmentCondition\n",
      "  Fat\n",
      "  Fatigue\n",
      "  Fever\n",
      "  Fish\n",
      "  FishingNet\n",
      "  FlatTerrain\n",
      "  Flour\n",
      "  Food\n",
      "  FoodAcquiring\n",
      "  FoodCategory\n",
      "  Fruit\n",
      "  Frying\n",
      "  Gluten\n",
      "  GlutenAllergy\n",
      "  GoodHearted\n",
      "  Grilling\n",
      "  Headache\n",
      "  Health\n",
      "  HelpsOthers\n",
      "  HigherEducation\n",
      "  HigherLearner\n",
      "  Infrastructure\n",
      "  Ingredient\n",
      "  IronDeficiency\n",
      "  Knife\n",
      "  Landmark\n",
      "  Lawyer\n",
      "  Lazy\n",
      "  Macaron\n",
      "  MarriedPerson\n",
      "  MedicalStudies\n",
      "  Microwave\n",
      "  MuscleAche\n",
      "  Nurse\n",
      "  Nut\n",
      "  NutAllergy\n",
      "  Nutrient\n",
      "  Obesity\n",
      "  Occupation\n",
      "  Olives\n",
      "  Oven\n",
      "  Pain\n",
      "  Pan\n",
      "  Pavement\n",
      "  Person\n",
      "  PrimaryEducation\n",
      "  PrimaryLearner\n",
      "  PrivateTransport\n",
      "  Protein\n",
      "  ProteinDeficiency\n",
      "  PublicTransport\n",
      "  QuietCity\n",
      "  RawFood\n",
      "  Reserved\n",
      "  Resource\n",
      "  Rice\n",
      "  Road\n",
      "  Seafood\n",
      "  SeafoodAllergy\n",
      "  SecondaryEducation\n",
      "  SecondaryLearner\n",
      "  SmallCity\n",
      "  Social\n",
      "  Spoon\n",
      "  Subway\n",
      "  SubwayStation\n",
      "  Sugar\n",
      "  Symptom\n",
      "  TakesRisks\n",
      "  Teacher\n",
      "  Terrain\n",
      "  Textbook\n",
      "  Tool\n",
      "  Transportation\n",
      "  Utility\n",
      "  Vitamins\n",
      "  Vlogger\n",
      "  Walkable\n",
      "  Walking\n",
      "  Water\n",
      "\n",
      "OBJECT PROPERTIES:\n",
      "  associatedHealthCondition | domain: ['City'] | range: ['(none)'] | type: Simple\n",
      "  attendedBy | domain: ['Education'] | range: ['Person'] | type: Simple\n",
      "  attends | domain: ['(none)'] | range: ['(none)'] | type: Simple\n",
      "  canEat | domain: ['(none)'] | range: ['Food', 'FoodCategory'] | type: Simple\n",
      "  containsIngredient | domain: ['(none)'] | range: ['Restriction(containsIngredient)'] | type: Simple\n",
      "  containsNutrient | domain: ['Food'] | range: ['Nutrient'] | type: Simple\n",
      "  derivedFrom | domain: ['Resource'] | range: ['Resource'] | type: Simple\n",
      "  excludesFoodCategory | domain: ['(none)'] | range: ['FoodCategory'] | type: Simple\n",
      "  famousForFood | domain: ['City'] | range: ['Food'] | type: Simple\n",
      "  hasAllergy | domain: ['Person'] | range: ['FoodCategory'] | type: Simple\n",
      "  hasEnvironmentCondition | domain: ['City'] | range: ['EnvironmentCondition'] | type: Simple\n",
      "  hasHealthCondition | domain: ['Person'] | range: ['(none)'] | type: Simple\n",
      "  hasLandmark | domain: ['City'] | range: ['Landmark'] | type: Simple\n",
      "  hasOccupation | domain: ['Person'] | range: ['Occupation'] | type: Functional\n",
      "  hasTerrain | domain: ['City'] | range: ['Terrain'] | type: Simple\n",
      "  hasTrait | domain: ['Person'] | range: ['CharacterTrait'] | type: Simple\n",
      "  impliesBehavior | domain: ['CharacterTrait'] | range: ['Behavior'] | type: Simple\n",
      "  isCookedAs | domain: ['Food'] | range: ['CookingMethod'] | type: Simple\n",
      "  isFriendOf | domain: ['Person'] | range: ['Person'] | type: Symmetric\n",
      "  isMarriedTo | domain: ['(none)'] | range: ['(none)'] | type: Symmetric\n",
      "  isOfCategory | domain: ['Food'] | range: ['FoodCategory'] | type: Simple\n",
      "  isQuiet | domain: ['(none)'] | range: ['City'] | type: Simple\n",
      "  isSimilarTo | domain: ['Food'] | range: ['Food'] | type: Symmetric\n",
      "  qualifiesForOccupation | domain: ['Education'] | range: ['Occupation'] | type: Simple\n",
      "  requiresEducationalResource | domain: ['Education'] | range: ['EducationalResource'] | type: Simple\n",
      "  requiresInfrastructure | domain: ['Transportation'] | range: ['Infrastructure'] | type: Simple\n",
      "  requiresIngredient | domain: ['(none)'] | range: ['(none)'] | type: Simple\n",
      "  requiresMethod | domain: ['(none)'] | range: ['(none)'] | type: Simple\n",
      "  requiresResource | domain: ['Tool'] | range: ['Resource'] | type: Simple\n",
      "  requiresResourceTool | domain: ['(none)'] | range: ['(none)'] | type: Simple\n",
      "  requiresTool | domain: ['Occupation'] | range: ['Tool'] | type: Simple\n",
      "  usedBy | domain: ['Transportation'] | range: ['Person'] | type: Simple\n",
      "\n",
      "DATA PROPERTIES:\n",
      "  builtInYear | domain: ['Landmark'] | range: ['int'] | type: Functional\n",
      "  hasAge | domain: ['(none)'] | range: ['int'] | type: Functional\n",
      "  hasHeight | domain: ['Landmark'] | range: ['int'] | type: Functional\n",
      "  hasName | domain: ['(none)'] | range: ['str'] | type: Functional\n",
      "  hasPopulation | domain: ['(none)'] | range: ['int'] | type: Functional\n",
      "  isDrivable | domain: ['(none)'] | range: ['bool'] | type: Functional\n",
      "  isWalkable | domain: ['(none)'] | range: ['bool'] | type: Functional\n",
      "\n",
      "INDIVIDUALS:\n",
      "  Adam : ['Person', 'Restriction(hasOccupation)']\n",
      "  Amelia : ['Thing', 'Restriction(hasHealthCondition)', 'Restriction(hasOccupation)']\n",
      "  Daan : ['Person']\n",
      "  Eiffel_Tower : ['Thing']\n",
      "  Elizabeth : ['Thing', 'Restriction(hasAllergy)', 'Restriction(hasHealthCondition)', 'Restriction(hasTrait)']\n",
      "  Jan : ['Person', 'Restriction(hasHealthCondition)', 'Restriction(hasTrait)']\n",
      "  Jasmin : ['Thing', 'Restriction(hasHealthCondition)', 'Restriction(hasOccupation)']\n",
      "  Jennifer : ['Thing', 'Restriction(hasOccupation)']\n",
      "  Kim : ['Thing', 'Restriction(attends)', 'Restriction(attends)', 'Restriction(hasHealthCondition)']\n",
      "  Los_Angeles : ['BigCity', 'BusyCity']\n",
      "  Paris : ['BigCity', 'City', 'Restriction(hasTerrain)']\n",
      "  Petra : ['Thing', 'Restriction(hasOccupation)']\n"
     ]
    }
   ],
   "source": [
    "from owlready2 import *\n",
    "\n",
    "def safe_name(x):\n",
    "    \"\"\"Return a readable name for any ontology element.\"\"\"\n",
    "    if hasattr(x, \"name\"):\n",
    "        return x.name\n",
    "    elif hasattr(x, \"__name__\"):\n",
    "        return x.__name__\n",
    "    elif isinstance(x, Restriction):\n",
    "        return f\"Restriction({x.property.name})\"\n",
    "    else:\n",
    "        return str(x)\n",
    "\n",
    "def get_ontology_summary():\n",
    "\n",
    "    summary = []\n",
    "    summary.append(f\"=== SUMMARY of {onto.base_iri} ===\\n\")\n",
    "\n",
    "    # --- CLASSES ---\n",
    "    summary.append(\"CLASSES:\")\n",
    "    for c in sorted(onto.classes(), key=lambda x: x.name):\n",
    "        summary.append(f\"  {c.name}\")\n",
    "\n",
    "    # --- OBJECT PROPERTIES ---\n",
    "    summary.append(\"\\nOBJECT PROPERTIES:\")\n",
    "    for p in sorted(onto.object_properties(), key=lambda x: x.name):\n",
    "        domain = [safe_name(d) for d in p.domain] or [\"(none)\"]\n",
    "        range_ = [safe_name(r) for r in p.range] or [\"(none)\"]\n",
    "\n",
    "        characteristics = []\n",
    "        if FunctionalProperty in p.is_a: characteristics.append(\"Functional\")\n",
    "        if InverseFunctionalProperty in p.is_a: characteristics.append(\"InverseFunctional\")\n",
    "        if SymmetricProperty in p.is_a: characteristics.append(\"Symmetric\")\n",
    "        if TransitiveProperty in p.is_a: characteristics.append(\"Transitive\")\n",
    "        info = \", \".join(characteristics) if characteristics else \"Simple\"\n",
    "\n",
    "        summary.append(f\"  {p.name} | domain: {domain} | range: {range_} | type: {info}\")\n",
    "\n",
    "    # --- DATA PROPERTIES ---\n",
    "    summary.append(\"\\nDATA PROPERTIES:\")\n",
    "    for p in sorted(onto.data_properties(), key=lambda x: x.name):\n",
    "        domain = [safe_name(d) for d in p.domain] or [\"(none)\"]\n",
    "        range_ = [safe_name(r) for r in p.range] or [\"(none)\"]\n",
    "\n",
    "        characteristics = []\n",
    "        if FunctionalProperty in p.is_a: characteristics.append(\"Functional\")\n",
    "        info = \", \".join(characteristics) if characteristics else \"Simple\"\n",
    "\n",
    "        summary.append(f\"  {p.name} | domain: {domain} | range: {range_} | type: {info}\")\n",
    "\n",
    "    # --- INDIVIDUALS ---\n",
    "    summary.append(\"\\nINDIVIDUALS:\")\n",
    "    for i in sorted(onto.individuals(), key=lambda x: x.name):\n",
    "        types = [safe_name(cls) for cls in i.is_a]\n",
    "        summary.append(f\"  {i.name} : {types}\")\n",
    "\n",
    "    return \"\\n\".join(summary)\n",
    "\n",
    "\n",
    "# Example usage\n",
    "print(get_ontology_summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a505ef60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk(state: InputState) -> InbetweenState:\n",
    "    \"\"\"Split the input into manageable chunks.\"\"\"\n",
    "    # split story in three parts\n",
    "    chunks = []\n",
    "\n",
    "    for sentence in state['story'].split(\".\"):\n",
    "        chunks.append(sentence.strip())\n",
    "\n",
    "    return {\"chunks\": chunks}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b9ada8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chunks': ['Naya walked in the garden',\n",
       "  'The flowers were bright',\n",
       "  'She smiled',\n",
       "  '']}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state = {\"story\": \"Amelia walked in the garden. The flowers were bright. He smiled.\"}\n",
    "\n",
    "# when\n",
    "result = chunk(state)\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8a81f8",
   "metadata": {},
   "source": [
    "# Extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9ca51684",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(state: InbetweenState)-> InbetweenState:\n",
    "    \"\"\"Extract relevant information from the story.\"\"\"\n",
    "    ontology_summary = get_ontology_summary()\n",
    "    story = state['story']\n",
    "\n",
    "    client = OpenAI()\n",
    "\n",
    "    class Triple(BaseModel):\n",
    "        subj: str\n",
    "        pred: str\n",
    "        obj: str\n",
    "\n",
    "    class Output(BaseModel):\n",
    "        output: list[Triple]\n",
    "\n",
    "    response = client.responses.parse(\n",
    "        model=\"gpt-5-nano\",\n",
    "        reasoning={\"effort\": \"low\"},\n",
    "        instructions=\"\"\"Look in the context that provides the classes, object types, data types and instances of an ontology. Then scan the story.\n",
    "        Which classes, object types, data types and instances you encounter in the story that are also present in the ontology_context?\n",
    "        ONLY use as predicates the ones that are present in the ontology_context.\"\"\",\n",
    "        input=f\"ontology_context: {ontology_summary}, story: {story}\",\n",
    "        text_format=Output\n",
    "    )\n",
    "\n",
    "    data = json.loads(response.output_text)\n",
    "\n",
    "    # Make a Python dict so it can be easily converted to JSON elsewhere\n",
    "    triples = data[\"output\"]\n",
    "\n",
    "    return {\"extract\": triples}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5347ef61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Extract result ---\n",
      "{\n",
      "  \"extract\": [\n",
      "    {\n",
      "      \"subj\": \"Amelia\",\n",
      "      \"pred\": \"hasOccupation\",\n",
      "      \"obj\": \"Lawyer\"\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "state = {\"story\": \"Amelia is lawyer and lives in Paris\"}\n",
    "result = extract(state)\n",
    "print(\"\\n--- Extract result ---\")\n",
    "print(json.dumps(result, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2328a3",
   "metadata": {},
   "source": [
    "# Check for conflicts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67fc7255",
   "metadata": {},
   "source": [
    "## helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "334a5e34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://IA.org/onto.owl#'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onto.base_iri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a2fa0f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_to_sparql(triple_dict, ontology_base_iri):\n",
    "    \"\"\"\n",
    "    Convert a dictionary like {'subj': 'Jorryt', 'pred': 'rdf:type', 'obj': 'Person'}\n",
    "    into a SPARQL query where the subject is replaced by a variable (?subject).\n",
    "    \"\"\"\n",
    "    prefix = f\"PREFIX : <{ontology_base_iri}>\\n\" \\\n",
    "             \"PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\\n\"\n",
    "\n",
    "    pred = triple_dict[\"pred\"]\n",
    "    obj = triple_dict[\"obj\"]\n",
    "\n",
    "    # If the predicate starts with \"rdf:\", keep it like that\n",
    "    # Otherwise prefix it with \":\"\n",
    "    pred_prefix = pred if pred.startswith(\"rdf:\") else f\":{pred}\"\n",
    "    obj_prefix = obj if obj.startswith(\"rdf:\") else f\":{obj}\"\n",
    "\n",
    "    query = prefix + f\"\"\"\n",
    "SELECT DISTINCT ?subject WHERE {{\n",
    "  ?subject {pred_prefix} {obj_prefix} .\n",
    "}}\n",
    "\"\"\"\n",
    "    return query\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a9a0b087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREFIX : <IA_ontology.owl>\n",
      "PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
      "\n",
      "SELECT DISTINCT ?subject WHERE {\n",
      "  ?subject rdf:type :Person .\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from textwrap import dedent\n",
    "\n",
    "\n",
    "def test_dict_to_sparql_basic():\n",
    "    triple = {\"subj\": \"Jorryt\", \"pred\": \"rdf:type\", \"obj\": \"Person\"}\n",
    "    base_iri = \"IA_ontology.owl\"\n",
    "\n",
    "    result = dict_to_sparql(triple, base_iri)\n",
    "    print(result)\n",
    "\n",
    "\n",
    "\n",
    "'''expected:\n",
    "    PREFIX : <IA_ontology.owl>\n",
    "    PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
    "\n",
    "    SELECT DISTINCT ?subject WHERE {\n",
    "      ?subject rdf:type :Person .\n",
    "    }\n",
    "\"\"\")'''\n",
    "\n",
    "test_dict_to_sparql_basic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "8334d663",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'subj': 'Amelia',\n",
       "  'pred': 'rdf:type',\n",
       "  'obj': 'Person',\n",
       "  'sparql_output': ['Adam',\n",
       "   'Daan',\n",
       "   'Jan',\n",
       "   'Amelia',\n",
       "   'Petra',\n",
       "   'Elizabeth',\n",
       "   'Jasmin',\n",
       "   'Jennifer']}]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def check_triples_against_ontology(triples, onto):\n",
    "\n",
    "    for triple in triples:\n",
    "        query = dict_to_sparql(triple, onto.base_iri)\n",
    "        # print(f\"Query:\\n{query}\")\n",
    "        try:\n",
    "            rows = list(default_world.sparql(query))\n",
    "            sparql_output_list = []\n",
    "            if rows:\n",
    "                # print(\"Output:\")\n",
    "                for row in rows:\n",
    "                    for x in row:\n",
    "                        sparql_output_list.append(x.name)\n",
    "            triple[\"sparql_output\"] = sparql_output_list\n",
    "        except Exception as e:\n",
    "            pass\n",
    "        #        print(\"-\" * 40)\n",
    "    return triples\n",
    "\n",
    "triples = [\n",
    "    {\n",
    "      \"subj\": \"Amelia\",\n",
    "      \"pred\": \"rdf:type\",\n",
    "      \"obj\": \"Person\"\n",
    "    }\n",
    "]\n",
    "\n",
    "results = check_triples_against_ontology(triples, onto)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "efaa7179",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'subj': 'Amelia',\n",
       "  'pred': 'rdf:type',\n",
       "  'obj': 'Person',\n",
       "  'sparql_output': ['Adam',\n",
       "   'Daan',\n",
       "   'Jan',\n",
       "   'Petra',\n",
       "   'Elizabeth',\n",
       "   'Jasmin',\n",
       "   'Jennifer'],\n",
       "  'valid': False}]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def scan_unvalid_triples(triples):\n",
    "    invalid_triples = []\n",
    "    for triple in triples:\n",
    "        if triple['sparql_output']:\n",
    "            if triple[\"subj\"] in triple[\"sparql_output\"]:\n",
    "                triple[\"valid\"] = True\n",
    "            else:\n",
    "                triple[\"valid\"] = False\n",
    "                invalid_triples.append(triple)\n",
    "    return invalid_triples\n",
    "\n",
    "\n",
    "triples = [{'subj': 'Amelia',\n",
    "  'pred': 'rdf:type',\n",
    "  'obj': 'Person',\n",
    "  'sparql_output': ['Adam',\n",
    "   'Daan',\n",
    "   'Jan',\n",
    "   'Petra',\n",
    "   'Elizabeth',\n",
    "   'Jasmin',\n",
    "   'Jennifer']}]\n",
    "scan_unvalid_triples(triples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaabbccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI()\n",
    "\n",
    "class Triple(BaseModel):\n",
    "    subj: str\n",
    "    pred: str\n",
    "    obj: str\n",
    "\n",
    "class Output(BaseModel):\n",
    "    output: list[Triple]\n",
    "\n",
    "response = client.responses.parse(\n",
    "    model=\"gpt-5-nano\",\n",
    "    reasoning={\"effort\": \"low\"},\n",
    "    instructions=\"\"\"\n",
    "\n",
    "    -\n",
    "\n",
    "    \"\"\",\n",
    "    input=f\"\"\"    We have seen for this text chunk the following inconsistencies with the ontology.\n",
    "\n",
    "    chunk: {chunk}\n",
    "\n",
    "    inconsistencies: {conflicts}\n",
    "\n",
    "    Please look at the ontology report and confirm or reject the inconsistencies.\n",
    "    ontology_context: {ontology_summary}\"\"\",\n",
    "    text_format=Output\n",
    ")\n",
    "\n",
    "data = json.loads(response.output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4401cd03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_conflicts(state: InbetweenState) -> InbetweenState:\n",
    "    \"\"\"Check for inconsistencies in the story.\"\"\"\n",
    "    onto = get_ontology(\"IA_ontology.owl\").load()\n",
    "    triples = [\n",
    "    {\n",
    "      \"subj\": \"sinterklaas\",\n",
    "      \"pred\": \"rdf:type\",\n",
    "      \"obj\": \"Person\"\n",
    "    }\n",
    "    ]\n",
    "\n",
    "    results = check_triples_against_ontology(triples, onto)\n",
    "    unvalid_triples = scan_unvalid_triples(results)\n",
    "    invalid_triples_str = \"\"\n",
    "    for triple in unvalid_triples:\n",
    "      invalid_triples_str += f\"sub: {triple['subj']}, pred: {triple['pred']}, obj: {triple['obj']}\\n\"\n",
    "\n",
    "    \n",
    "    return {\"conflicts\": unvalid_triples}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "6321d57e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unvalid triples: [{'subj': 'sinterklaas', 'pred': 'rdf:type', 'obj': 'Person', 'sparql_output': ['Adam', 'Daan', 'Jan', 'Amelia', 'Petra', 'Elizabeth', 'Jasmin', 'Jennifer'], 'valid': False}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'conflicts': [{'subj': 'sinterklaas',\n",
       "   'pred': 'rdf:type',\n",
       "   'obj': 'Person',\n",
       "   'sparql_output': ['Adam',\n",
       "    'Daan',\n",
       "    'Jan',\n",
       "    'Amelia',\n",
       "    'Petra',\n",
       "    'Elizabeth',\n",
       "    'Jasmin',\n",
       "    'Jennifer'],\n",
       "   'valid': False}]}"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state = {\n",
    "    \"extract\": [\n",
    "        {\"subj\": \"Amelia\", \"pred\": \"rdf:type\", \"obj\": \"Person\"},\n",
    "        {\"subj\": \"Daan\", \"pred\": \"rdf:type\", \"obj\": \"Person\"},\n",
    "        {\"subj\": \"Paris\", \"pred\": \"rdf:type\", \"obj\": \"City\"},\n",
    "        {\"subj\": \"Eiffel_Tower\", \"pred\": \"builtInYear\", \"obj\": \"int\"},\n",
    "        {\"subj\": \"Paris\", \"pred\": \"hasPopulation\", \"obj\": \"int\"}\n",
    "            ]\n",
    "}\n",
    "\n",
    "check_conflicts(state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "f1dd0ecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sub: sinterklaas, pred: rdf:type, obj: Person\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print the sub, pred, obj of the triples that are invalid as a big string with flags\n",
    "conflicts = {'conflicts': [{'subj': 'sinterklaas',\n",
    "   'pred': 'rdf:type',\n",
    "   'obj': 'Person',\n",
    "   'sparql_output': ['Adam',\n",
    "    'Daan',\n",
    "    'Jan',\n",
    "    'Amelia',\n",
    "    'Petra',\n",
    "    'Elizabeth',\n",
    "    'Jasmin',\n",
    "    'Jennifer'],\n",
    "   'valid': False}]}\n",
    "\n",
    "invalid_triples_str = \"\"\n",
    "for triple in conflicts['conflicts']:\n",
    "    invalid_triples_str += f\"sub: {triple['subj']}, pred: {triple['pred']}, obj: {triple['obj']}\\n\"\n",
    "\n",
    "print(invalid_triples_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e822bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
