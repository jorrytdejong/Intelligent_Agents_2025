{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "292ae775",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24b99805",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import START, END, StateGraph\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from IPython.display import Image, display\n",
    "from langgraph.graph import MessagesState\n",
    "from langchain_core.messages import SystemMessage\n",
    "from owlready2 import get_ontology\n",
    "from langchain_core.messages import AIMessage\n",
    "from langgraph.prebuilt import tools_condition\n",
    "from pathlib import Path\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from pydantic import BaseModel\n",
    "from typing import List, Optional\n",
    "\n",
    "from owlready2 import *\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a10593",
   "metadata": {},
   "source": [
    "setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c19acb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MockLLM:\n",
    "    def invoke(self, messages):\n",
    "        return \"mocked assistant response\"\n",
    "\n",
    "llm_with_tools = MockLLM()\n",
    "sys_msg = SystemMessage(content=\"You are a helpful assistant.\")\n",
    "onto = get_ontology(\"IA_ontology.owl\").load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4048319",
   "metadata": {},
   "source": [
    "Define Pydantic classes for input, inbetween and output states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4608cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputState(TypedDict):\n",
    "    story: str\n",
    "\n",
    "class InbetweenState(TypedDict):\n",
    "    story: str\n",
    "    chunks: list[str]\n",
    "    ontology_summary: str\n",
    "    extract: list[str]\n",
    "    conflicts: list[str]\n",
    "    rewritten_chunks: list[str]\n",
    "    re_verified_chunks: list[str]\n",
    "    evaluated_chunks: list[str]\n",
    "\n",
    "\n",
    "class OutputState(TypedDict):\n",
    "    revised_story: str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b235885e",
   "metadata": {},
   "source": [
    "Functions to make a summary of the ontology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62a26e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use IA_ontology.owl\n",
    "onto = get_ontology(\"IA_ontology.owl\").load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4676b968",
   "metadata": {},
   "source": [
    "# Getting Ontology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9af02b45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== SUMMARY of http://IA.org/onto.owl# ===\n",
      "\n",
      "CLASSES:\n",
      "  Activity\n",
      "  Adult\n",
      "  Adventurous\n",
      "  Allergy\n",
      "  AvoidsSocialInteraction\n",
      "  AvoidsTasks\n",
      "  Baguette\n",
      "  Baker\n",
      "  Baking\n",
      "  Behavior\n",
      "  Bicycle\n",
      "  BicycleLane\n",
      "  BigCity\n",
      "  Boiling\n",
      "  Bus\n",
      "  BusStation\n",
      "  BusyCity\n",
      "  Cake\n",
      "  Cancer\n",
      "  Car\n",
      "  Carbohydrate\n",
      "  Cashier\n",
      "  CatchingFish\n",
      "  CharacterTrait\n",
      "  Chef\n",
      "  City\n",
      "  Classroom\n",
      "  Condition\n",
      "  CookedFood\n",
      "  CookingMethod\n",
      "  Croissant\n",
      "  CuttingBoard\n",
      "  Dairy\n",
      "  DairyAllergy\n",
      "  Deficiency\n",
      "  Dessert\n",
      "  Diabetes\n",
      "  Disease\n",
      "  Doctor\n",
      "  Education\n",
      "  EducationalResource\n",
      "  Electricity\n",
      "  ElectricityUtility\n",
      "  EnvironmentCondition\n",
      "  Fat\n",
      "  Fatigue\n",
      "  Fever\n",
      "  Fish\n",
      "  FishingNet\n",
      "  FlatTerrain\n",
      "  Flour\n",
      "  Food\n",
      "  FoodAcquiring\n",
      "  FoodCategory\n",
      "  Fruit\n",
      "  Frying\n",
      "  Gluten\n",
      "  GlutenAllergy\n",
      "  GoodHearted\n",
      "  Grilling\n",
      "  Headache\n",
      "  Health\n",
      "  HelpsOthers\n",
      "  HigherEducation\n",
      "  HigherLearner\n",
      "  Infrastructure\n",
      "  Ingredient\n",
      "  IronDeficiency\n",
      "  Knife\n",
      "  Landmark\n",
      "  Lawyer\n",
      "  Lazy\n",
      "  Macaron\n",
      "  MarriedPerson\n",
      "  MedicalStudies\n",
      "  Microwave\n",
      "  MuscleAche\n",
      "  Nurse\n",
      "  Nut\n",
      "  NutAllergy\n",
      "  Nutrient\n",
      "  Obesity\n",
      "  Occupation\n",
      "  Olives\n",
      "  Oven\n",
      "  Pain\n",
      "  Pan\n",
      "  Pavement\n",
      "  Person\n",
      "  PrimaryEducation\n",
      "  PrimaryLearner\n",
      "  PrivateTransport\n",
      "  Protein\n",
      "  ProteinDeficiency\n",
      "  PublicTransport\n",
      "  QuietCity\n",
      "  RawFood\n",
      "  Reserved\n",
      "  Resource\n",
      "  Rice\n",
      "  Road\n",
      "  Seafood\n",
      "  SeafoodAllergy\n",
      "  SecondaryEducation\n",
      "  SecondaryLearner\n",
      "  SmallCity\n",
      "  Social\n",
      "  Spoon\n",
      "  Subway\n",
      "  SubwayStation\n",
      "  Sugar\n",
      "  Symptom\n",
      "  TakesRisks\n",
      "  Teacher\n",
      "  Terrain\n",
      "  Textbook\n",
      "  Tool\n",
      "  Transportation\n",
      "  Utility\n",
      "  Vitamins\n",
      "  Vlogger\n",
      "  Walkable\n",
      "  Walking\n",
      "  Water\n",
      "\n",
      "OBJECT PROPERTIES:\n",
      "  associatedHealthCondition | domain: ['City'] | range: ['(none)'] | type: Simple\n",
      "  attendedBy | domain: ['Education'] | range: ['Person'] | type: Simple\n",
      "  attends | domain: ['(none)'] | range: ['(none)'] | type: Simple\n",
      "  canEat | domain: ['(none)'] | range: ['Food', 'FoodCategory'] | type: Simple\n",
      "  containsIngredient | domain: ['(none)'] | range: ['Restriction(containsIngredient)'] | type: Simple\n",
      "  containsNutrient | domain: ['Food'] | range: ['Nutrient'] | type: Simple\n",
      "  derivedFrom | domain: ['Resource'] | range: ['Resource'] | type: Simple\n",
      "  excludesFoodCategory | domain: ['(none)'] | range: ['FoodCategory'] | type: Simple\n",
      "  famousForFood | domain: ['City'] | range: ['Food'] | type: Simple\n",
      "  hasAllergy | domain: ['Person'] | range: ['FoodCategory'] | type: Simple\n",
      "  hasEnvironmentCondition | domain: ['City'] | range: ['EnvironmentCondition'] | type: Simple\n",
      "  hasHealthCondition | domain: ['Person'] | range: ['(none)'] | type: Simple\n",
      "  hasLandmark | domain: ['City'] | range: ['Landmark'] | type: Simple\n",
      "  hasOccupation | domain: ['Person'] | range: ['Occupation'] | type: Functional\n",
      "  hasTerrain | domain: ['City'] | range: ['Terrain'] | type: Simple\n",
      "  hasTrait | domain: ['Person'] | range: ['CharacterTrait'] | type: Simple\n",
      "  impliesBehavior | domain: ['CharacterTrait'] | range: ['Behavior'] | type: Simple\n",
      "  isCookedAs | domain: ['Food'] | range: ['CookingMethod'] | type: Simple\n",
      "  isFriendOf | domain: ['Person'] | range: ['Person'] | type: Symmetric\n",
      "  isMarriedTo | domain: ['(none)'] | range: ['(none)'] | type: Symmetric\n",
      "  isOfCategory | domain: ['Food'] | range: ['FoodCategory'] | type: Simple\n",
      "  isQuiet | domain: ['(none)'] | range: ['City'] | type: Simple\n",
      "  isSimilarTo | domain: ['Food'] | range: ['Food'] | type: Symmetric\n",
      "  qualifiesForOccupation | domain: ['Education'] | range: ['Occupation'] | type: Simple\n",
      "  requiresEducationalResource | domain: ['Education'] | range: ['EducationalResource'] | type: Simple\n",
      "  requiresInfrastructure | domain: ['Transportation'] | range: ['Infrastructure'] | type: Simple\n",
      "  requiresIngredient | domain: ['(none)'] | range: ['(none)'] | type: Simple\n",
      "  requiresMethod | domain: ['(none)'] | range: ['(none)'] | type: Simple\n",
      "  requiresResource | domain: ['Tool'] | range: ['Resource'] | type: Simple\n",
      "  requiresResourceTool | domain: ['(none)'] | range: ['(none)'] | type: Simple\n",
      "  requiresTool | domain: ['Occupation'] | range: ['Tool'] | type: Simple\n",
      "  usedBy | domain: ['Transportation'] | range: ['Person'] | type: Simple\n",
      "\n",
      "DATA PROPERTIES:\n",
      "  builtInYear | domain: ['Landmark'] | range: ['int'] | type: Functional\n",
      "  hasAge | domain: ['(none)'] | range: ['int'] | type: Functional\n",
      "  hasHeight | domain: ['Landmark'] | range: ['int'] | type: Functional\n",
      "  hasName | domain: ['(none)'] | range: ['str'] | type: Functional\n",
      "  hasPopulation | domain: ['(none)'] | range: ['int'] | type: Functional\n",
      "  isDrivable | domain: ['(none)'] | range: ['bool'] | type: Functional\n",
      "  isWalkable | domain: ['(none)'] | range: ['bool'] | type: Functional\n",
      "\n",
      "INDIVIDUALS:\n",
      "  Adam : ['Person', 'Restriction(hasOccupation)']\n",
      "  Amelia : ['Thing', 'Restriction(hasHealthCondition)', 'Restriction(hasOccupation)']\n",
      "  Daan : ['Person']\n",
      "  Eiffel_Tower : ['Thing']\n",
      "  Elizabeth : ['Thing', 'Restriction(hasAllergy)', 'Restriction(hasHealthCondition)', 'Restriction(hasTrait)']\n",
      "  Jan : ['Person', 'Restriction(hasHealthCondition)', 'Restriction(hasTrait)']\n",
      "  Jasmin : ['Thing', 'Restriction(hasHealthCondition)', 'Restriction(hasOccupation)']\n",
      "  Jennifer : ['Thing', 'Restriction(hasOccupation)']\n",
      "  Kim : ['Thing', 'Restriction(attends)', 'Restriction(attends)', 'Restriction(hasHealthCondition)']\n",
      "  Los_Angeles : ['BigCity', 'BusyCity']\n",
      "  Paris : ['BigCity', 'City', 'Restriction(hasTerrain)']\n",
      "  Petra : ['Thing', 'Restriction(hasOccupation)']\n"
     ]
    }
   ],
   "source": [
    "from owlready2 import *\n",
    "\n",
    "def safe_name(x):\n",
    "    \"\"\"Return a readable name for any ontology element.\"\"\"\n",
    "    if hasattr(x, \"name\"):\n",
    "        return x.name\n",
    "    elif hasattr(x, \"__name__\"):\n",
    "        return x.__name__\n",
    "    elif isinstance(x, Restriction):\n",
    "        return f\"Restriction({x.property.name})\"\n",
    "    else:\n",
    "        return str(x)\n",
    "\n",
    "def get_ontology_summary():\n",
    "\n",
    "    summary = []\n",
    "    summary.append(f\"=== SUMMARY of {onto.base_iri} ===\\n\")\n",
    "\n",
    "    # --- CLASSES ---\n",
    "    summary.append(\"CLASSES:\")\n",
    "    for c in sorted(onto.classes(), key=lambda x: x.name):\n",
    "        summary.append(f\"  {c.name}\")\n",
    "\n",
    "    # --- OBJECT PROPERTIES ---\n",
    "    summary.append(\"\\nOBJECT PROPERTIES:\")\n",
    "    for p in sorted(onto.object_properties(), key=lambda x: x.name):\n",
    "        domain = [safe_name(d) for d in p.domain] or [\"(none)\"]\n",
    "        range_ = [safe_name(r) for r in p.range] or [\"(none)\"]\n",
    "\n",
    "        characteristics = []\n",
    "        if FunctionalProperty in p.is_a: characteristics.append(\"Functional\")\n",
    "        if InverseFunctionalProperty in p.is_a: characteristics.append(\"InverseFunctional\")\n",
    "        if SymmetricProperty in p.is_a: characteristics.append(\"Symmetric\")\n",
    "        if TransitiveProperty in p.is_a: characteristics.append(\"Transitive\")\n",
    "        info = \", \".join(characteristics) if characteristics else \"Simple\"\n",
    "\n",
    "        summary.append(f\"  {p.name} | domain: {domain} | range: {range_} | type: {info}\")\n",
    "\n",
    "    # --- DATA PROPERTIES ---\n",
    "    summary.append(\"\\nDATA PROPERTIES:\")\n",
    "    for p in sorted(onto.data_properties(), key=lambda x: x.name):\n",
    "        domain = [safe_name(d) for d in p.domain] or [\"(none)\"]\n",
    "        range_ = [safe_name(r) for r in p.range] or [\"(none)\"]\n",
    "\n",
    "        characteristics = []\n",
    "        if FunctionalProperty in p.is_a: characteristics.append(\"Functional\")\n",
    "        info = \", \".join(characteristics) if characteristics else \"Simple\"\n",
    "\n",
    "        summary.append(f\"  {p.name} | domain: {domain} | range: {range_} | type: {info}\")\n",
    "\n",
    "    # --- INDIVIDUALS ---\n",
    "    summary.append(\"\\nINDIVIDUALS:\")\n",
    "    for i in sorted(onto.individuals(), key=lambda x: x.name):\n",
    "        types = [safe_name(cls) for cls in i.is_a]\n",
    "        summary.append(f\"  {i.name} : {types}\")\n",
    "\n",
    "    return \"\\n\".join(summary)\n",
    "\n",
    "\n",
    "# Example usage\n",
    "print(get_ontology_summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c962d951",
   "metadata": {},
   "source": [
    "# Chunk Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a505ef60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk(state: InputState) -> InbetweenState:\n",
    "    \"\"\"Split the input into manageable chunks.\"\"\"\n",
    "    # split story in three parts\n",
    "    chunks = []\n",
    "\n",
    "    for sentence in state['story'].split(\".\"):\n",
    "        chunks.append(sentence.strip())\n",
    "\n",
    "    return {\"chunks\": chunks}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "59b9ada8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chunks': ['Adam, a baker living in Paris, spent the early morning baking fresh croissants and baguettes, carefully using his favorite oven and knife to prepare dough that was rich in flour and butter',\n",
       "  'His friend Jan, who had a mild gluten allergy but a good heart, still visited the bakery every weekend, walking through the quiet parts of the city to enjoy the smell of freshly baked bread',\n",
       "  'Later that evening, Adam flew to Mars to sell his pastries to astronauts in a floating space café above Olympus Mons',\n",
       "  '\"']}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state = {\"story\": \"\"\"\n",
    "\n",
    "Adam, a baker living in Paris, spent the early morning baking fresh croissants and baguettes, carefully using his favorite oven and knife to prepare dough that was rich in flour and butter.\n",
    "His friend Jan, who had a mild gluten allergy but a good heart, still visited the bakery every weekend, walking through the quiet parts of the city to enjoy the smell of freshly baked bread.\n",
    "Later that evening, Adam flew to Mars to sell his pastries to astronauts in a floating space café above Olympus Mons.\"\n",
    "\n",
    "\n",
    "\"\"\"}\n",
    "\n",
    "# when\n",
    "result = chunk(state)\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c9a16297",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "def get_triples(ontology_summary, chunk):    \n",
    "    client = OpenAI()\n",
    "\n",
    "    class Triple(BaseModel):\n",
    "        subj: str\n",
    "        pred: str\n",
    "        obj: str\n",
    "\n",
    "    class Output(BaseModel):\n",
    "        output: list[Triple]\n",
    "\n",
    "    response = client.responses.parse(\n",
    "        model=\"gpt-5-mini\",\n",
    "        reasoning={\"effort\": \"medium\"},\n",
    "        instructions=\"\"\"Look in the context that provides the classes, object types, data types and instances of an ontology. Then scan the story.\n",
    "        Which classes, object types, data types and instances you encounter in the story that are also present in the ontology_context?\n",
    "        ONLY use as predicates the ones that are present in the ontology_context.\"\"\",\n",
    "        input=f\"ontology_context: {ontology_summary}, story: {chunk}\",\n",
    "        text_format=Output\n",
    "    )\n",
    "\n",
    "    data = json.loads(response.output_text)\n",
    "\n",
    "    # Make a Python dict so it can be easily converted to JSON elsewhere\n",
    "    triples = data[\"output\"]\n",
    "\n",
    "    return triples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8a81f8",
   "metadata": {},
   "source": [
    "# Extract Node"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f2020f",
   "metadata": {},
   "source": [
    "This node is extracting triples from each separate chunk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9ca51684",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(state: InbetweenState)-> InbetweenState:\n",
    "    \"\"\"Extract relevant information from the story.\"\"\"\n",
    "    ontology_summary = get_ontology_summary()\n",
    "\n",
    "    extracts_dict = {}\n",
    "    for i,chunk in enumerate(state['chunks']):\n",
    "        print(f\"Extracting triples from chunk {i}\")\n",
    "        print(f\"Chunk: {chunk}\")\n",
    "        triples = get_triples(ontology_summary, chunk)\n",
    "        print(f\"Triples: {triples}\")\n",
    "        extracts_dict[f'chunk_{i}'] = triples\n",
    "\n",
    "    return {\"extract\": extracts_dict}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5347ef61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting triples from chunk 0\n",
      "Chunk: Adam, a baker living in Paris, spent the early morning baking fresh croissants and baguettes, carefully using his favorite oven and knife to prepare dough that was rich in flour and butter\n",
      "Triples: [{'subj': 'Adam', 'pred': 'hasOccupation', 'obj': 'Baker'}, {'subj': 'Baker', 'pred': 'requiresTool', 'obj': 'Oven'}, {'subj': 'Baker', 'pred': 'requiresTool', 'obj': 'Knife'}, {'subj': 'Croissant', 'pred': 'isCookedAs', 'obj': 'Baking'}, {'subj': 'Baguette', 'pred': 'isCookedAs', 'obj': 'Baking'}, {'subj': 'Paris', 'pred': 'famousForFood', 'obj': 'Croissant'}, {'subj': 'Paris', 'pred': 'famousForFood', 'obj': 'Baguette'}, {'subj': 'Croissant', 'pred': 'containsIngredient', 'obj': 'Flour'}, {'subj': 'Baguette', 'pred': 'containsIngredient', 'obj': 'Flour'}, {'subj': 'Adam', 'pred': 'hasName', 'obj': 'Adam'}]\n",
      "Extracting triples from chunk 1\n",
      "Chunk: His friend Jan, who had a mild gluten allergy but a good heart, still visited the bakery every weekend, walking through the quiet parts of the city to enjoy the smell of freshly baked bread\n",
      "Triples: [{'subj': 'Jan', 'pred': 'hasAllergy', 'obj': 'GlutenAllergy'}, {'subj': 'Jan', 'pred': 'hasTrait', 'obj': 'GoodHearted'}, {'subj': 'Jan', 'pred': 'isFriendOf', 'obj': 'Petra'}, {'subj': 'Walking', 'pred': 'usedBy', 'obj': 'Jan'}, {'subj': 'Jan', 'pred': 'attends', 'obj': 'FoodAcquiring'}, {'subj': 'QuietCity', 'pred': 'isQuiet', 'obj': 'Paris'}]\n",
      "Extracting triples from chunk 2\n",
      "Chunk: Later that evening, Adam flew to Mars to sell his pastries to astronauts in a floating space café above Olympus Mons\n",
      "Triples: [{'subj': 'Adam', 'pred': 'hasName', 'obj': 'Adam'}, {'subj': 'Petra', 'pred': 'hasName', 'obj': 'Petra'}]\n",
      "Extracting triples from chunk 3\n",
      "Chunk: \"\n",
      "Triples: []\n",
      "\n",
      "--- Extract result ---\n",
      "{\n",
      "  \"extract\": {\n",
      "    \"chunk_0\": [\n",
      "      {\n",
      "        \"subj\": \"Adam\",\n",
      "        \"pred\": \"hasOccupation\",\n",
      "        \"obj\": \"Baker\"\n",
      "      },\n",
      "      {\n",
      "        \"subj\": \"Baker\",\n",
      "        \"pred\": \"requiresTool\",\n",
      "        \"obj\": \"Oven\"\n",
      "      },\n",
      "      {\n",
      "        \"subj\": \"Baker\",\n",
      "        \"pred\": \"requiresTool\",\n",
      "        \"obj\": \"Knife\"\n",
      "      },\n",
      "      {\n",
      "        \"subj\": \"Croissant\",\n",
      "        \"pred\": \"isCookedAs\",\n",
      "        \"obj\": \"Baking\"\n",
      "      },\n",
      "      {\n",
      "        \"subj\": \"Baguette\",\n",
      "        \"pred\": \"isCookedAs\",\n",
      "        \"obj\": \"Baking\"\n",
      "      },\n",
      "      {\n",
      "        \"subj\": \"Paris\",\n",
      "        \"pred\": \"famousForFood\",\n",
      "        \"obj\": \"Croissant\"\n",
      "      },\n",
      "      {\n",
      "        \"subj\": \"Paris\",\n",
      "        \"pred\": \"famousForFood\",\n",
      "        \"obj\": \"Baguette\"\n",
      "      },\n",
      "      {\n",
      "        \"subj\": \"Croissant\",\n",
      "        \"pred\": \"containsIngredient\",\n",
      "        \"obj\": \"Flour\"\n",
      "      },\n",
      "      {\n",
      "        \"subj\": \"Baguette\",\n",
      "        \"pred\": \"containsIngredient\",\n",
      "        \"obj\": \"Flour\"\n",
      "      },\n",
      "      {\n",
      "        \"subj\": \"Adam\",\n",
      "        \"pred\": \"hasName\",\n",
      "        \"obj\": \"Adam\"\n",
      "      }\n",
      "    ],\n",
      "    \"chunk_1\": [\n",
      "      {\n",
      "        \"subj\": \"Jan\",\n",
      "        \"pred\": \"hasAllergy\",\n",
      "        \"obj\": \"GlutenAllergy\"\n",
      "      },\n",
      "      {\n",
      "        \"subj\": \"Jan\",\n",
      "        \"pred\": \"hasTrait\",\n",
      "        \"obj\": \"GoodHearted\"\n",
      "      },\n",
      "      {\n",
      "        \"subj\": \"Jan\",\n",
      "        \"pred\": \"isFriendOf\",\n",
      "        \"obj\": \"Petra\"\n",
      "      },\n",
      "      {\n",
      "        \"subj\": \"Walking\",\n",
      "        \"pred\": \"usedBy\",\n",
      "        \"obj\": \"Jan\"\n",
      "      },\n",
      "      {\n",
      "        \"subj\": \"Jan\",\n",
      "        \"pred\": \"attends\",\n",
      "        \"obj\": \"FoodAcquiring\"\n",
      "      },\n",
      "      {\n",
      "        \"subj\": \"QuietCity\",\n",
      "        \"pred\": \"isQuiet\",\n",
      "        \"obj\": \"Paris\"\n",
      "      }\n",
      "    ],\n",
      "    \"chunk_2\": [\n",
      "      {\n",
      "        \"subj\": \"Adam\",\n",
      "        \"pred\": \"hasName\",\n",
      "        \"obj\": \"Adam\"\n",
      "      },\n",
      "      {\n",
      "        \"subj\": \"Petra\",\n",
      "        \"pred\": \"hasName\",\n",
      "        \"obj\": \"Petra\"\n",
      "      }\n",
      "    ],\n",
      "    \"chunk_3\": []\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "state = {'chunks': ['Adam, a baker living in Paris, spent the early morning baking fresh croissants and baguettes, carefully using his favorite oven and knife to prepare dough that was rich in flour and butter',\n",
    "  'His friend Jan, who had a mild gluten allergy but a good heart, still visited the bakery every weekend, walking through the quiet parts of the city to enjoy the smell of freshly baked bread',\n",
    "  'Later that evening, Adam flew to Mars to sell his pastries to astronauts in a floating space café above Olympus Mons',\n",
    "  '\"']}\n",
    "result = extract(state)\n",
    "print(\"\\n--- Extract result ---\")\n",
    "print(json.dumps(result, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2328a3",
   "metadata": {},
   "source": [
    "# Check for conflicts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67fc7255",
   "metadata": {},
   "source": [
    "## helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025eba9a",
   "metadata": {},
   "source": [
    "This helper function makes a simple Sparql query that will check whether the subject of the triple is really related to the object by the predicate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a2fa0f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_to_sparql(triple_dict, ontology_base_iri):\n",
    "    \"\"\"\n",
    "    Convert a dictionary like {'subj': 'Jorryt', 'pred': 'rdf:type', 'obj': 'Person'}\n",
    "    into a SPARQL query where the subject is replaced by a variable (?subject).\n",
    "    \"\"\"\n",
    "    prefix = f\"PREFIX : <{ontology_base_iri}>\\n\" \\\n",
    "             \"PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\\n\"\n",
    "\n",
    "    pred = triple_dict[\"pred\"]\n",
    "    obj = triple_dict[\"obj\"]\n",
    "\n",
    "    # If the predicate starts with \"rdf:\", keep it like that\n",
    "    # Otherwise prefix it with \":\"\n",
    "    pred_prefix = pred if pred.startswith(\"rdf:\") else f\":{pred}\"\n",
    "    obj_prefix = obj if obj.startswith(\"rdf:\") else f\":{obj}\"\n",
    "\n",
    "    query = prefix + f\"\"\"\n",
    "SELECT DISTINCT ?subject WHERE {{\n",
    "  ?subject {pred_prefix} {obj_prefix} .\n",
    "}}\n",
    "\"\"\"\n",
    "    return query\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a9a0b087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREFIX : <IA_ontology.owl>\n",
      "PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
      "\n",
      "SELECT DISTINCT ?subject WHERE {\n",
      "  ?subject rdf:type :Person .\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from textwrap import dedent\n",
    "\n",
    "\n",
    "def test_dict_to_sparql_basic():\n",
    "    triple = {\"subj\": \"Jorryt\", \"pred\": \"rdf:type\", \"obj\": \"Person\"}\n",
    "    base_iri = \"IA_ontology.owl\"\n",
    "\n",
    "    result = dict_to_sparql(triple, base_iri)\n",
    "    print(result)\n",
    "\n",
    "\n",
    "\n",
    "'''expected:\n",
    "    PREFIX : <IA_ontology.owl>\n",
    "    PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
    "\n",
    "    SELECT DISTINCT ?subject WHERE {\n",
    "      ?subject rdf:type :Person .\n",
    "    }\n",
    "\"\"\")'''\n",
    "\n",
    "test_dict_to_sparql_basic()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7b720a",
   "metadata": {},
   "source": [
    "This function prints the outcomes of the SPARQL query for the triple in a new dictionary key-item pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8334d663",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'subj': 'Amelia',\n",
       "  'pred': 'rdf:type',\n",
       "  'obj': 'Person',\n",
       "  'sparql_output': ['Adam', 'Daan', 'Jan']}]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def check_triples_against_ontology(triples, onto):\n",
    "\n",
    "    for triple in triples:\n",
    "        query = dict_to_sparql(triple, onto.base_iri)\n",
    "        # print(f\"Query:\\n{query}\")\n",
    "        try:\n",
    "            rows = list(default_world.sparql(query))\n",
    "            sparql_output_list = []\n",
    "            if rows:\n",
    "                # print(\"Output:\")\n",
    "                for row in rows:\n",
    "                    for x in row:\n",
    "                        sparql_output_list.append(x.name)\n",
    "            triple[\"sparql_output\"] = sparql_output_list\n",
    "        except Exception as e:\n",
    "            pass\n",
    "        #        print(\"-\" * 40)\n",
    "    return triples\n",
    "\n",
    "triples = [\n",
    "    {\n",
    "      \"subj\": \"Amelia\",\n",
    "      \"pred\": \"rdf:type\",\n",
    "      \"obj\": \"Person\"\n",
    "    }\n",
    "]\n",
    "\n",
    "results = check_triples_against_ontology(triples, onto)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59436d2c",
   "metadata": {},
   "source": [
    "This helper function will check whether the subject is in the output of the SPARQL query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "efaa7179",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'subj': 'Amelia',\n",
       "  'pred': 'rdf:type',\n",
       "  'obj': 'Person',\n",
       "  'sparql_output': ['Adam',\n",
       "   'Daan',\n",
       "   'Jan',\n",
       "   'Petra',\n",
       "   'Elizabeth',\n",
       "   'Jasmin',\n",
       "   'Jennifer'],\n",
       "  'valid': False}]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def scan_unvalid_triples(triples):\n",
    "    invalid_triples = []\n",
    "    for triple in triples:\n",
    "        if triple['sparql_output']:\n",
    "            if triple[\"subj\"] in triple[\"sparql_output\"]:\n",
    "                triple[\"valid\"] = True\n",
    "            else:\n",
    "                triple[\"valid\"] = False\n",
    "                invalid_triples.append(triple)\n",
    "    return invalid_triples\n",
    "\n",
    "\n",
    "triples = [{'subj': 'Amelia',\n",
    "  'pred': 'rdf:type',\n",
    "  'obj': 'Person',\n",
    "  'sparql_output': ['Adam',\n",
    "   'Daan',\n",
    "   'Jan',\n",
    "   'Petra',\n",
    "   'Elizabeth',\n",
    "   'Jasmin',\n",
    "   'Jennifer']}]\n",
    "scan_unvalid_triples(triples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "097071c9",
   "metadata": {},
   "source": [
    "This LLM-driven function checks the inconsistency. And, with help of the ontology in the context, makes the conflicts clearer and gives explanation and suggestion for resolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "eaabbccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "def get_conflicts(ontology_summary, invalid_triples_str, valid_triples_str):\n",
    "\n",
    "    client = OpenAI()\n",
    "\n",
    "    class Conflict(BaseModel):\n",
    "        conflict: str = Field(description=\"The conflict that is found in the text chunk.\")\n",
    "        explanation: str = Field(description=\"The explanation for the conflict.\")\n",
    "        resolution: str = Field(description=\"The resolution for the conflict.\")\n",
    "\n",
    "    class Output(BaseModel):\n",
    "        output: list[Conflict]\n",
    "\n",
    "    response = client.responses.parse(\n",
    "        model=\"gpt-5-nano\",\n",
    "        reasoning={\"effort\": \"low\"},\n",
    "        instructions=\"\"\"\n",
    "\n",
    "        -\n",
    "\n",
    "        \"\"\",\n",
    "        input=f\"\"\"    We have seen for this text chunk the following inconsistencies with the ontology.\n",
    "\n",
    "        chunk: {chunk}\n",
    "\n",
    "        inconsistencies: {invalid_triples_str}\n",
    "\n",
    "        consistent triples: {valid_triples_str}\n",
    "\n",
    "        Please look at the ontology report and confirm or reject the inconsistencies.\n",
    "        ontology_context: {ontology_summary}\"\"\",\n",
    "        text_format=Output\n",
    "    )\n",
    "\n",
    "    data = json.loads(response.output_text)\n",
    "    return data\n",
    "\n",
    "# ontology_summary = get_ontology_summary()\n",
    "# unvalid_triples = scan_unvalid_triples(results)\n",
    "# invalid_triples_str = \"\"\n",
    "# for triple in unvalid_triples:\n",
    "#   invalid_triples_str += f\"sub: {triple['subj']}, pred: {triple['pred']}, obj: {triple['obj']}\\n\"\n",
    "\n",
    "\n",
    "\n",
    "# # take the valid triples\n",
    "# valid_triples = [triple for triple in results if triple['valid']]\n",
    "# conflicts = get_conflicts(ontology_summary, invalid_triples_str)\n",
    "# conflicts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4401cd03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_conflicts(state: InbetweenState) -> InbetweenState:\n",
    "    \"\"\"Check for inconsistencies in the story.\"\"\"\n",
    "    onto = get_ontology(\"IA_ontology.owl\").load()\n",
    "\n",
    "    conflicts = {}\n",
    "\n",
    "    for chunk_name, chunk_triples in result['extract'].items():\n",
    "    \n",
    "      results = check_triples_against_ontology(chunk_triples, onto)\n",
    "      unvalid_triples = scan_unvalid_triples(results)\n",
    "      invalid_triples_str = \"\"\n",
    "      # make a string of the invalid triples\n",
    "      for triple in unvalid_triples:\n",
    "        invalid_triples_str += f\"sub: {triple['subj']}, pred: {triple['pred']}, obj: {triple['obj']}\\n\"\n",
    "\n",
    "      for triple in results:\n",
    "        print(f\"triple: {triple}\")\n",
    "\n",
    "\n",
    "      # make a string of the valid triples\n",
    "      '''valid_triples = [triple for triple in results if triple['valid']]\n",
    "      valid_triples_str = \"\"\n",
    "      for triple in valid_triples:\n",
    "        valid_triples_str += f\"sub: {triple['subj']}, pred: {triple['pred']}, obj: {triple['obj']}\\n\"'''\n",
    "\n",
    "\n",
    "      ontology_summary = get_ontology_summary()\n",
    "      conflics_for_chunk = get_conflicts(ontology_summary, invalid_triples_str, valid_triples_str)\n",
    "      conflicts[chunk_name] = conflics_for_chunk\n",
    "\n",
    "    \n",
    "    return {\"conflicts\": conflicts}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6321d57e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "triple: {'subj': 'Adam', 'pred': 'hasOccupation', 'obj': 'Baker', 'sparql_output': []}\n",
      "triple: {'subj': 'Baker', 'pred': 'requiresTool', 'obj': 'Oven', 'sparql_output': []}\n",
      "triple: {'subj': 'Baker', 'pred': 'requiresTool', 'obj': 'Knife', 'sparql_output': []}\n",
      "triple: {'subj': 'Croissant', 'pred': 'isCookedAs', 'obj': 'Baking', 'sparql_output': []}\n",
      "triple: {'subj': 'Baguette', 'pred': 'isCookedAs', 'obj': 'Baking', 'sparql_output': []}\n",
      "triple: {'subj': 'Paris', 'pred': 'famousForFood', 'obj': 'Croissant', 'sparql_output': []}\n",
      "triple: {'subj': 'Paris', 'pred': 'famousForFood', 'obj': 'Baguette', 'sparql_output': []}\n",
      "triple: {'subj': 'Croissant', 'pred': 'containsIngredient', 'obj': 'Flour', 'sparql_output': []}\n",
      "triple: {'subj': 'Baguette', 'pred': 'containsIngredient', 'obj': 'Flour', 'sparql_output': []}\n",
      "triple: {'subj': 'Adam', 'pred': 'hasName', 'obj': 'Adam', 'sparql_output': []}\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'valid_triples_str' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[58]\u001b[39m\u001b[32m, line 103\u001b[39m\n\u001b[32m      1\u001b[39m state = {\n\u001b[32m      2\u001b[39m   \u001b[33m\"\u001b[39m\u001b[33mextract\u001b[39m\u001b[33m\"\u001b[39m: {\n\u001b[32m      3\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mchunk_0\u001b[39m\u001b[33m\"\u001b[39m: [\n\u001b[32m   (...)\u001b[39m\u001b[32m    100\u001b[39m   }\n\u001b[32m    101\u001b[39m }\n\u001b[32m--> \u001b[39m\u001b[32m103\u001b[39m \u001b[43mcheck_conflicts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[57]\u001b[39m\u001b[32m, line 28\u001b[39m, in \u001b[36mcheck_conflicts\u001b[39m\u001b[34m(state)\u001b[39m\n\u001b[32m     21\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m'''valid_triples = [triple for triple in results if triple['valid']]\u001b[39;00m\n\u001b[32m     22\u001b[39m \u001b[33;03m  valid_triples_str = \"\"\u001b[39;00m\n\u001b[32m     23\u001b[39m \u001b[33;03m  for triple in valid_triples:\u001b[39;00m\n\u001b[32m     24\u001b[39m \u001b[33;03m    valid_triples_str += f\"sub: {triple['subj']}, pred: {triple['pred']}, obj: {triple['obj']}\\n\"'''\u001b[39;00m\n\u001b[32m     27\u001b[39m   ontology_summary = get_ontology_summary()\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m   conflics_for_chunk = get_conflicts(ontology_summary, invalid_triples_str, \u001b[43mvalid_triples_str\u001b[49m)\n\u001b[32m     29\u001b[39m   conflicts[chunk_name] = conflics_for_chunk\n\u001b[32m     32\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[33m\"\u001b[39m\u001b[33mconflicts\u001b[39m\u001b[33m\"\u001b[39m: conflicts}\n",
      "\u001b[31mNameError\u001b[39m: name 'valid_triples_str' is not defined"
     ]
    }
   ],
   "source": [
    "state = {\n",
    "  \"extract\": {\n",
    "    \"chunk_0\": [\n",
    "      {\n",
    "        \"subj\": \"Adam\",\n",
    "        \"pred\": \"hasOccupation\",\n",
    "        \"obj\": \"Baker\"\n",
    "      },\n",
    "      {\n",
    "        \"subj\": \"Baker\",\n",
    "        \"pred\": \"requiresTool\",\n",
    "        \"obj\": \"Oven\"\n",
    "      },\n",
    "      {\n",
    "        \"subj\": \"Baker\",\n",
    "        \"pred\": \"requiresTool\",\n",
    "        \"obj\": \"Knife\"\n",
    "      },\n",
    "      {\n",
    "        \"subj\": \"Croissant\",\n",
    "        \"pred\": \"isCookedAs\",\n",
    "        \"obj\": \"Baking\"\n",
    "      },\n",
    "      {\n",
    "        \"subj\": \"Baguette\",\n",
    "        \"pred\": \"isCookedAs\",\n",
    "        \"obj\": \"Baking\"\n",
    "      },\n",
    "      {\n",
    "        \"subj\": \"Paris\",\n",
    "        \"pred\": \"famousForFood\",\n",
    "        \"obj\": \"Croissant\"\n",
    "      },\n",
    "      {\n",
    "        \"subj\": \"Paris\",\n",
    "        \"pred\": \"famousForFood\",\n",
    "        \"obj\": \"Baguette\"\n",
    "      },\n",
    "      {\n",
    "        \"subj\": \"Croissant\",\n",
    "        \"pred\": \"containsIngredient\",\n",
    "        \"obj\": \"Flour\"\n",
    "      },\n",
    "      {\n",
    "        \"subj\": \"Baguette\",\n",
    "        \"pred\": \"containsIngredient\",\n",
    "        \"obj\": \"Flour\"\n",
    "      },\n",
    "      {\n",
    "        \"subj\": \"Adam\",\n",
    "        \"pred\": \"hasName\",\n",
    "        \"obj\": \"Adam\"\n",
    "      }\n",
    "    ],\n",
    "    \"chunk_1\": [\n",
    "      {\n",
    "        \"subj\": \"Jan\",\n",
    "        \"pred\": \"hasAllergy\",\n",
    "        \"obj\": \"GlutenAllergy\"\n",
    "      },\n",
    "      {\n",
    "        \"subj\": \"Jan\",\n",
    "        \"pred\": \"hasTrait\",\n",
    "        \"obj\": \"GoodHearted\"\n",
    "      },\n",
    "      {\n",
    "        \"subj\": \"Jan\",\n",
    "        \"pred\": \"isFriendOf\",\n",
    "        \"obj\": \"Petra\"\n",
    "      },\n",
    "      {\n",
    "        \"subj\": \"Walking\",\n",
    "        \"pred\": \"usedBy\",\n",
    "        \"obj\": \"Jan\"\n",
    "      },\n",
    "      {\n",
    "        \"subj\": \"Jan\",\n",
    "        \"pred\": \"attends\",\n",
    "        \"obj\": \"FoodAcquiring\"\n",
    "      },\n",
    "      {\n",
    "        \"subj\": \"QuietCity\",\n",
    "        \"pred\": \"isQuiet\",\n",
    "        \"obj\": \"Paris\"\n",
    "      }\n",
    "    ],\n",
    "    \"chunk_2\": [\n",
    "      {\n",
    "        \"subj\": \"Adam\",\n",
    "        \"pred\": \"hasName\",\n",
    "        \"obj\": \"Adam\"\n",
    "      },\n",
    "      {\n",
    "        \"subj\": \"Petra\",\n",
    "        \"pred\": \"hasName\",\n",
    "        \"obj\": \"Petra\"\n",
    "      }\n",
    "    ],\n",
    "    \"chunk_3\": []\n",
    "  }\n",
    "}\n",
    "\n",
    "check_conflicts(state)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8205a3",
   "metadata": {},
   "source": [
    "# Rewrite\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
