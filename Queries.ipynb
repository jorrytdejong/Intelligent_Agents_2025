{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "decb4712-cae5-4d7b-8274-e2016c248303",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "# ============================== Imports ==============================\n",
    "from owlready2 import get_ontology, default_world\n",
    "from typing_extensions import TypedDict\n",
    "from pydantic import BaseModel\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Dict, Tuple, Any, Optional, Iterable\n",
    "from collections import defaultdict, deque\n",
    "from datetime import datetime\n",
    "import argparse\n",
    "import sys\n",
    "import re\n",
    "import csv\n",
    "import json\n",
    "import os\n",
    "import html\n",
    "import ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2d18dcda-0d16-42e4-bf60-fae0b3b00e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ============================ Data Structures ============================\n",
    "class InputState(TypedDict):\n",
    "    story: str\n",
    "\n",
    "class InbetweenState(TypedDict):\n",
    "    story: str\n",
    "    chunks: List[str]\n",
    "    ontology_summary: str\n",
    "    extract: Dict[str, List[Dict[str, str]]]\n",
    "    conflicts: Dict[str, List[Dict[str, str]]]\n",
    "    rewritten_chunks: List[str]\n",
    "    re_verified_chunks: List[str]\n",
    "    evaluated_chunks: List[str]\n",
    "\n",
    "class OutputState(TypedDict):\n",
    "    revised_story: str\n",
    "\n",
    "class Triple(BaseModel):\n",
    "    subj: str\n",
    "    pred: str\n",
    "    obj: str\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class Metrics:\n",
    "    tp: int\n",
    "    tn: int\n",
    "    fp: int\n",
    "    fn: int\n",
    "    precision: float\n",
    "    recall: float\n",
    "    f1: float\n",
    "    accuracy: float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c26b60a5-ec63-4a63-9312-8132da11b4de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Ontology Loaded ===\n",
      "Base IRI: http://IA.org/onto.owl#\n",
      "Classes: ['Education', 'Person', 'Food', 'FoodCategory', 'Nutrient', 'Resource', 'Allergy', 'City', 'EnvironmentCondition', 'Condition', 'Landmark', 'Occupation', 'Utility', 'Terrain', 'CharacterTrait', 'Behavior', 'CookingMethod', 'Adult', 'EducationalResource', 'Transportation', 'Infrastructure', 'Tool', 'Activity', 'Adventurous', 'TakesRisks', 'AvoidsSocialInteraction', 'Social', 'AvoidsTasks', 'Baguette', 'Gluten', 'Oven', 'Baker', 'Baking', 'Bicycle', 'PrivateTransport', 'BicycleLane', 'BigCity', 'SmallCity', 'Boiling', 'Bus', 'PublicTransport', 'BusStation', 'BusyCity', 'QuietCity', 'Cake', 'Nut', 'Cancer', 'Disease', 'Car', 'Carbohydrate', 'Cashier', 'CatchingFish', 'FoodAcquiring', 'FishingNet', 'Chef', 'Classroom', 'Health', 'CookedFood', 'Croissant', 'Rice', 'Microwave', 'Flour', 'CuttingBoard', 'Dairy', 'DairyAllergy', 'Deficiency', 'Dessert', 'Vitamins', 'Diabetes', 'Doctor', 'EiffelTowerLandmark', 'Electricity', 'NoElectricity', 'Fat', 'Fatigue', 'Symptom', 'Fever', 'Fish', 'Ingredient', 'Sugar', 'FlatTerrain', 'Walkable', 'Frying', 'GlutenAllergy', 'GoodHearted', 'HelpsOthers', 'Grilling', 'Headache', 'HeightEiffelTower', 'HigherEducation', 'Lawyer', 'HigherLearner', 'IronDeficiency', 'Knife', 'Lazy', 'Macaron', 'MarriedPerson', 'MedicalStudies', 'MuscleAche', 'Nurse', 'NutAllergy', 'Obesity', 'Olives', 'Pain', 'Pan', 'Pavement', 'PrimaryEducation', 'PrimaryLearner', 'Protein', 'ProteinDeficiency', 'RawFood', 'Reserved', 'Road', 'Seafood', 'SeafoodAllergy', 'SecondaryEducation', 'SecondaryLearner', 'Spoon', 'Subway', 'SubwayStation', 'Teacher', 'Textbook', 'Vlogger', 'Walking', 'Water']\n",
      "Individuals: ['Adam', 'Amelia', 'Apple', 'Nuts', 'Car1', 'Dessert1', 'Eiffel_Tower', 'Paris', 'Elizabeth', 'Jan', 'Jennifer', 'Kim', 'Los_Angeles', 'Macaron1', 'Microwave1', 'Pear', 'Pomegranate']\n",
      "Object Properties: ['associatedHealthCondition', 'attendedBy', 'attends', 'canEat', 'containsIngredient', 'containsNutrient', 'derivedFrom', 'excludesFoodCategory', 'famousForFood', 'hasAllergy', 'hasEnvironmentCondition', 'hasHealthCondition', 'hasLandmark', 'hasOccupation', 'hasResourceStatus', 'hasTerrain', 'hasTrait', 'impliesBehavior', 'isCookedAs', 'isFriendOf', 'isLocatedIn', 'isMarriedTo', 'isOfCategory', 'isQuiet', 'isSimilarTo', 'qualifiesForOccupation', 'requiresEducationalResource', 'requiresInfrastructure', 'requiresIngredient', 'requiresMethod', 'requiresResource', 'requiresResourceTool', 'requiresTool', 'usedBy']\n",
      "Data Properties: ['builtInYear', 'hasAge', 'hasHeight', 'hasName', 'hasPopulation', 'isDrivable', 'isWalkable']\n"
     ]
    }
   ],
   "source": [
    "#-----------------------ONTOLOGY\n",
    "ONTOLOGY_PATH = \"/home/izujia/Desktop/Intelligent_Agents/owl/IA_ontology4.owl\"  # <- adjust if needed\n",
    "onto = get_ontology(ONTOLOGY_PATH).load()\n",
    "\n",
    "EX = getattr(onto, \"base_iri\", \"http://IA.org/onto.owl#\").rstrip(\"#\") + \"#\"\n",
    "PREFIX_EX = f\"PREFIX ex: <{EX}>\"\n",
    "PREFIX_XSD = \"PREFIX xsd: <http://www.w3.org/2001/XMLSchema#>\"\n",
    "\n",
    "print(\"=== Ontology Loaded ===\")\n",
    "print(\"Base IRI:\", EX)\n",
    "print(\"Classes:\", [c.name for c in onto.classes()])\n",
    "print(\"Individuals:\", [i.name for i in onto.individuals()])\n",
    "print(\"Object Properties:\", [p.name for p in onto.object_properties()])\n",
    "print(\"Data Properties:\", [p.name for p in onto.data_properties()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "92a4cd3d-1dd9-4aac-bec0-beee2e081e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================== Utilities ==============================\n",
    "def _canon(s: str) -> str:\n",
    "    return \" \".join(str(s).strip().split()).lower()\n",
    "\n",
    "def _strip_iri(x: str) -> str:\n",
    "    if not x:\n",
    "        return x\n",
    "    return str(x).split(\".\")[-1].split(\"/\")[-1].split(\"#\")[-1]\n",
    "\n",
    "def _norm_obj(x: str) -> str:\n",
    "    return _canon(_strip_iri(x))\n",
    "\n",
    "def _norm_pred(x: str) -> str:\n",
    "    x = _canon(x)\n",
    "    return {\n",
    "        \"islocatedin\": \"islocatedin\",\n",
    "        \"hasage\": \"hasage\",\n",
    "        \"hasoccupation\": \"hasoccupation\",\n",
    "        \"hastrait\": \"hastrait\",\n",
    "        \"haspopulation\": \"haspopulation\",\n",
    "        \"description\": \"description\",\n",
    "        \"requiresresource\": \"requiresresource\",\n",
    "        \"requirestool\": \"requirestool\",\n",
    "        \"ismarriedto\": \"ismarriedto\",\n",
    "        \"hasresourcestatus\": \"hasresourcestatus\",\n",
    "    }.get(x, x)\n",
    "\n",
    "def _to_int_maybe(x: str) -> Optional[int]:\n",
    "    try:\n",
    "        return int(x)\n",
    "    except Exception:\n",
    "        num = \"\"\n",
    "        for ch in str(x):\n",
    "            if ch.isdigit():\n",
    "                num += ch\n",
    "            elif num:\n",
    "                break\n",
    "        return int(num) if num else None\n",
    "\n",
    "def _safe_ratio(num: int | float, den: int | float) -> float:\n",
    "    return float(num) / float(den) if den else 0.0\n",
    "\n",
    "def _label_of(gold: int, pred: int) -> str:\n",
    "    if gold == 1 and pred == 1: return \"TP\"\n",
    "    if gold == 0 and pred == 0: return \"TN\"\n",
    "    if gold == 0 and pred == 1: return \"FP\"\n",
    "    return \"FN\"\n",
    "\n",
    "# ============================== Step 1: Chunk ==============================\n",
    "def chunk(state: InputState) -> InbetweenState:\n",
    "    sentences = re.split(r'(?<=[.!?])\\s+', state['story'].strip())\n",
    "    chunks = [s.strip() for s in sentences if s.strip()]\n",
    "    print(\"\\n=== Node: Chunk ===\")\n",
    "    print(chunks)\n",
    "    return {\n",
    "        \"story\": state['story'],\n",
    "        \"chunks\": chunks,\n",
    "        \"ontology_summary\": \"\",\n",
    "        \"extract\": {},\n",
    "        \"conflicts\": {},\n",
    "        \"rewritten_chunks\": [],\n",
    "        \"re_verified_chunks\": [],\n",
    "        \"evaluated_chunks\": []\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "166d3483-9db2-4396-bb7b-4963f38f9767",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================== Step 2: Extract ==============================\n",
    "def extract(state: InbetweenState) -> InbetweenState:\n",
    "    print(\"\\n=== Node: Extract Triples ===\")\n",
    "    extracts: Dict[str, List[Dict[str, str]]] = {}\n",
    "    previous_subject: Optional[str] = None\n",
    "    onto_inds = {i.name for i in onto.individuals()}\n",
    "\n",
    "    def norm_subj(s: str) -> str:\n",
    "        s = s.strip()\n",
    "        if s in {\"She\", \"He\"} and previous_subject:\n",
    "            return previous_subject\n",
    "        s = s.title()\n",
    "        if s not in onto_inds and s.endswith(\"s\") and s[:-1] in onto_inds:\n",
    "            s = s[:-1]\n",
    "        return s\n",
    "\n",
    "    for i, chunk_text in enumerate(state['chunks']):\n",
    "        triples: List[Dict[str, str]] = []\n",
    "        seen_triples = set()\n",
    "\n",
    "        m_subj = re.search(r'\\b([A-Z][a-z]+)\\b', chunk_text)\n",
    "        if m_subj:\n",
    "            previous_subject = m_subj.group(1)\n",
    "\n",
    "        # Age\n",
    "        for m in re.finditer(r'\\b(She|He|[A-Z][a-z]+)\\s+is\\s+(\\d{1,3})\\s+years?\\s+old', chunk_text):\n",
    "            subj = norm_subj(m.group(1))\n",
    "            triples.append({\"subj\": subj, \"pred\": \"hasAge\", \"obj\": m.group(2)})\n",
    "\n",
    "        # Marriage\n",
    "        for m in re.finditer(r'\\b(She|He|[A-Z][a-z]+)\\b.*?married.*?\\b([A-Z][a-z]+)\\b', chunk_text):\n",
    "            subj = norm_subj(m.group(1))\n",
    "            triples.append({\"subj\": subj, \"pred\": \"isMarriedTo\", \"obj\": norm_subj(m.group(2))})\n",
    "\n",
    "        # City description\n",
    "        for m in re.finditer(r'\\b([A-Z][A-Za-z]+(?:\\s[A-Z][A-Za-z]+)?)\\s+(?:is\\s+a\\s+|has\\s+a\\s+.*?\\s+and\\s+is\\s+a\\s+)?(quiet|empty|calm|busy|noisy|crowded)',\n",
    "                             chunk_text, flags=re.IGNORECASE):\n",
    "            city_raw = m.group(1).strip()\n",
    "            city = city_raw.replace(' ', '_')\n",
    "            desc = m.group(2).lower()\n",
    "            t = (city, \"description\", desc)\n",
    "            if t not in seen_triples:\n",
    "                triples.append({\"subj\": city, \"pred\": \"description\", \"obj\": desc})\n",
    "                seen_triples.add(t)\n",
    "\n",
    "        # Occupation\n",
    "        for m in re.finditer(r'\\b([A-Z][a-z]+)\\b.*?\\b(?:works\\s+as|is\\s+a|is\\s+an|became)\\s+([A-Za-z][A-Za-z\\s\\-]+?)(?:[.,;]|$)',\n",
    "                             chunk_text, flags=re.IGNORECASE):\n",
    "            subj = norm_subj(m.group(1))\n",
    "            occ = m.group(2).strip()\n",
    "            if re.search(r'\\b(married|allergic|allergy|peanut|peanuts|pizza|sandwich|reserved person|quiet|empty|city)\\b',\n",
    "                         occ, flags=re.IGNORECASE):\n",
    "                continue\n",
    "            t = (subj, \"hasOccupation\", occ)\n",
    "            if t not in seen_triples:\n",
    "                triples.append({\"subj\": subj, \"pred\": \"hasOccupation\", \"obj\": occ})\n",
    "                seen_triples.add(t)\n",
    "\n",
    "        # Traits\n",
    "        trait_pat = (r'(([A-Z][a-z]+)\\'s\\s+(?:husband|wife|spouse)\\s+describes\\s+(?:her|him|them)\\s+as\\s+a?\\s+([A-Za-z\\s\\-]+?)\\s+person'\n",
    "                     r'|\\b([A-Z][a-z]+|She|He)\\s+is\\s+(reserved|social|goodhearted|lazy))')\n",
    "        for m in re.finditer(trait_pat, chunk_text, flags=re.IGNORECASE):\n",
    "            if m.group(2):\n",
    "                subj_raw = m.group(2)\n",
    "                trait_raw = m.group(3)\n",
    "            else:\n",
    "                subj_raw = m.group(4)\n",
    "                trait_raw = m.group(5)\n",
    "            subj = norm_subj(subj_raw)\n",
    "            trait = trait_raw.replace('-', ' ').strip()\n",
    "            trait = trait.title().replace(' ', '_')\n",
    "            t = (subj, \"hasTrait\", trait)\n",
    "            if t not in seen_triples:\n",
    "                triples.append({\"subj\": subj, \"pred\": \"hasTrait\", \"obj\": trait})\n",
    "                seen_triples.add(t)\n",
    "\n",
    "        # Location\n",
    "        for m in re.finditer(r'\\b([A-Z][\\w]+(?:\\s[A-Z][\\w]+)*)\\s+is\\s+(?:located\\s+in|in|at)\\s+([A-Z][\\w]+(?:\\s[A-Z][\\w]+)*)\\.?',\n",
    "                             chunk_text, flags=re.IGNORECASE):\n",
    "            subj_raw = m.group(1).strip()\n",
    "            obj_raw = m.group(2).strip()\n",
    "            subj_words = subj_raw.split()\n",
    "            if subj_words and subj_words[0] in {\"The\", \"A\", \"An\"}:\n",
    "                subj_raw = \" \".join(subj_words[1:])\n",
    "            if not subj_raw:\n",
    "                continue\n",
    "            subj = subj_raw.replace(' ', '_')\n",
    "            obj = norm_subj(obj_raw).replace(' ', '_')\n",
    "            t = (subj, \"isLocatedIn\", obj)\n",
    "            if t not in seen_triples:\n",
    "                triples.append({\"subj\": subj, \"pred\": \"isLocatedIn\", \"obj\": obj})\n",
    "                seen_triples.add(t)\n",
    "\n",
    "        # No electricity\n",
    "        for m in re.finditer(r'\\b(?:no|without|lack\\s+of)\\s+([A-Za-z]+)\\s+in\\s+([A-Z][a-z]+)\\b',\n",
    "                             chunk_text, flags=re.IGNORECASE):\n",
    "            resource = m.group(1).title()\n",
    "            location = m.group(2).title().replace(' ', '_')\n",
    "            status = 'NoElectricity' if resource == 'Electricity' else f'No{resource}'\n",
    "            t = (location, \"hasResourceStatus\", status)\n",
    "            if t not in seen_triples:\n",
    "                triples.append({\"subj\": location, \"pred\": \"hasResourceStatus\", \"obj\": status})\n",
    "                seen_triples.add(t)\n",
    "\n",
    "        # Population\n",
    "        for m in re.finditer(r'\\b([A-Z][a-z]+(?:\\s+[A-Z][a-z]+)*)\\s+has\\s+(?:a\\s+)?(high|low|large|small)\\s+population\\b',\n",
    "                             chunk_text, flags=re.IGNORECASE):\n",
    "            subj = m.group(1).replace(' ', '_')\n",
    "            pop = m.group(2).lower()\n",
    "            t = (subj, \"hasPopulation\", pop)\n",
    "            if t not in seen_triples:\n",
    "                triples.append({\"subj\": subj, \"pred\": \"hasPopulation\", \"obj\": pop})\n",
    "                seen_triples.add(t)\n",
    "\n",
    "        # Tools\n",
    "        for m in re.finditer(r'\\b(croissants|baguettes|cake|macaron|food)\\s+.*?\\b(?:made|prepared)\\s+in\\s+the\\s+(oven|stove|pan)\\b',\n",
    "                             chunk_text, flags=re.IGNORECASE):\n",
    "            tool = m.group(2).title()\n",
    "            activity = {'Oven': 'Baking', 'Stove': 'Cooking'}.get(tool, 'Activity')\n",
    "            t = (activity, \"requiresTool\", tool)\n",
    "            if t not in seen_triples:\n",
    "                triples.append({\"subj\": activity, \"pred\": \"requiresTool\", \"obj\": tool})\n",
    "                seen_triples.add(t)\n",
    "\n",
    "        extracts[f\"chunk_{i}\"] = triples\n",
    "        print(f\"chunk_{i} -> {triples}\")\n",
    "\n",
    "    state['extract'] = extracts\n",
    "    return state\n",
    "\n",
    "# ======================= Step 3: Check Conflicts (SPARQL+rules) =======================\n",
    "_EIFFEL_ALIASES = {\"eiffel_tower\", \"eiffel tower\", \"eiffel\"}\n",
    "\n",
    "def _sparql(q: str):\n",
    "    # Owlready2 default_world.sparql returns a generator-like; cast to list safely\n",
    "    return list(default_world.sparql(q, error_on_undefined_entities=False))\n",
    "\n",
    "def check_conflicts(state: InbetweenState) -> InbetweenState:\n",
    "    print(\"\\n=== Node: Check Conflicts with SPARQL ===\")\n",
    "    conflicts: Dict[str, List[Dict[str, str]]] = {}\n",
    "\n",
    "    for chunk_name, triples in state['extract'].items():\n",
    "        chunk_conflicts: List[Dict[str, str]] = []\n",
    "\n",
    "        for t in triples:\n",
    "            subj = _strip_iri(t['subj']).replace(' ', '_')\n",
    "            pred = _norm_pred(t['pred'])\n",
    "            obj  = _strip_iri(t['obj']).replace(' ', '_')\n",
    "\n",
    "            # --- Rule-style checks (deterministic, fast) ---\n",
    "            # Age < 18\n",
    "            if pred == \"hasage\":\n",
    "                age = _to_int_maybe(obj)\n",
    "                if age is None or age < 18:\n",
    "                    chunk_conflicts.append(t)\n",
    "                    continue\n",
    "\n",
    "            # Eiffel Tower location\n",
    "            if pred == \"islocatedin\" and _canon(subj) in _EIFFEL_ALIASES:\n",
    "                if _canon(obj) != \"paris\":\n",
    "                    chunk_conflicts.append(t)\n",
    "                    continue\n",
    "\n",
    "            # City quiet vs high/large pop: cross-validation happens in evaluation; here, try ontology class check if available\n",
    "            if pred == \"description\" and obj in {\"quiet\", \"empty\", \"calm\"}:\n",
    "                q = f\"\"\"\n",
    "{PREFIX_EX}\n",
    "SELECT ?city WHERE {{\n",
    "  BIND(ex:{subj} AS ?city) .\n",
    "  ?city a ?cls .\n",
    "  FILTER(STRAFTER(STR(?cls), \"#\") IN (\"BusyCity\",\"CrowdedCity\",\"NoisyCity\"))\n",
    "}}\n",
    "\"\"\"\n",
    "                try:\n",
    "                    if _sparql(q):\n",
    "                        chunk_conflicts.append(t)\n",
    "                        continue\n",
    "                except Exception as e:\n",
    "                    print(f\"[SPARQL warn] BusyCity check failed for {subj}: {e}\")\n",
    "\n",
    "            # --- Ontology lookups bound to the actual subject ---\n",
    "\n",
    "            if pred == \"islocatedin\":\n",
    "                q = f\"\"\"\n",
    "{PREFIX_EX}\n",
    "SELECT ?loc WHERE {{\n",
    "  BIND(ex:{subj} AS ?ind) .\n",
    "  ?ind ex:isLocatedIn ?loc .\n",
    "}}\n",
    "\"\"\"\n",
    "                try:\n",
    "                    results = _sparql(q)\n",
    "                    if not results:\n",
    "                        # unknown in ontology → flag as conflict candidate\n",
    "                        chunk_conflicts.append(t)\n",
    "                    else:\n",
    "                        onto_locs = {_strip_iri(r[0]) for r in results}\n",
    "                        if obj not in onto_locs:\n",
    "                            chunk_conflicts.append(t)\n",
    "                except Exception as e:\n",
    "                    print(f\"[SPARQL warn] isLocatedIn check failed for {subj}: {e}\")\n",
    "                    chunk_conflicts.append(t)\n",
    "                continue  # avoid running a second generic query below\n",
    "\n",
    "            if pred == \"hastrait\":\n",
    "                q = f\"\"\"\n",
    "{PREFIX_EX}\n",
    "SELECT ?trait WHERE {{\n",
    "  BIND(ex:{subj} AS ?ind) .\n",
    "  ?ind ex:hasTrait ?trait .\n",
    "}}\n",
    "\"\"\"\n",
    "                try:\n",
    "                    results = _sparql(q)\n",
    "                    if results:\n",
    "                        onto_traits = {_strip_iri(r[0]) for r in results}\n",
    "                        if obj not in onto_traits:\n",
    "                            chunk_conflicts.append(t)\n",
    "                    else:\n",
    "                        chunk_conflicts.append(t)\n",
    "                except Exception as e:\n",
    "                    print(f\"[SPARQL warn] hasTrait check failed for {subj}: {e}\")\n",
    "                    chunk_conflicts.append(t)\n",
    "                continue\n",
    "\n",
    "            if pred == \"hasresourcestatus\" and obj == \"NoElectricity\":\n",
    "                # If ontology states some method requiring electricity while city has NoElectricity, it's a potential conflict –\n",
    "                # but the *pairing* is evaluated later. Here, flag presence to drive rewriting.\n",
    "                # Optionally verify Oven requires Electricity:\n",
    "                q = f\"\"\"\n",
    "{PREFIX_EX}\n",
    "SELECT ?res WHERE {{\n",
    "  ex:Oven ex:requiresResource ?res .\n",
    "}}\n",
    "\"\"\"\n",
    "                try:\n",
    "                    results = _sparql(q)\n",
    "                    if results:\n",
    "                        required = {_strip_iri(r[0]).lower() for r in results}\n",
    "                        if \"electricity\" in required:\n",
    "                            chunk_conflicts.append(t)\n",
    "                    else:\n",
    "                        chunk_conflicts.append(t)\n",
    "                except Exception as e:\n",
    "                    print(f\"[SPARQL warn] requiresResource(Oven) failed: {e}\")\n",
    "                    chunk_conflicts.append(t)\n",
    "                continue\n",
    "\n",
    "            if pred == \"requirestool\":\n",
    "                # Check method-tool pairing exists\n",
    "                q = f\"\"\"\n",
    "{PREFIX_EX}\n",
    "SELECT ?tool WHERE {{\n",
    "  ex:{subj} a ex:CookingMethod ;\n",
    "            ex:requiresTool ?tool .\n",
    "}}\n",
    "\"\"\"\n",
    "                try:\n",
    "                    results = _sparql(q)\n",
    "                    if results:\n",
    "                        tools = {_strip_iri(r[0]) for r in results}\n",
    "                        if obj not in tools:\n",
    "                            chunk_conflicts.append(t)\n",
    "                    else:\n",
    "                        chunk_conflicts.append(t)\n",
    "                except Exception as e:\n",
    "                    print(f\"[SPARQL warn] requiresTool check failed for {subj}: {e}\")\n",
    "                    chunk_conflicts.append(t)\n",
    "                continue\n",
    "\n",
    "            if pred == \"hasoccupation\":\n",
    "                # If ontology constrains single occupation, check if >1 exists for this person.\n",
    "                q = f\"\"\"\n",
    "{PREFIX_EX}\n",
    "SELECT (COUNT(DISTINCT ?occ) AS ?n) WHERE {{\n",
    "  ex:{subj} ex:hasOccupation ?occ .\n",
    "}}\n",
    "\"\"\"\n",
    "                try:\n",
    "                    results = _sparql(q)\n",
    "                    if results:\n",
    "                        # results[0][0] is an rdflib Literal; compare as int if possible\n",
    "                        n_txt = str(results[0][0])\n",
    "                        n_val = _to_int_maybe(n_txt)\n",
    "                        if n_val and n_val > 1:\n",
    "                            chunk_conflicts.append(t)\n",
    "                    else:\n",
    "                        # unknown person/occupation → cannot verify → treat as conflict to be conservative\n",
    "                        chunk_conflicts.append(t)\n",
    "                except Exception as e:\n",
    "                    print(f\"[SPARQL warn] hasOccupation count failed for {subj}: {e}\")\n",
    "                    chunk_conflicts.append(t)\n",
    "                continue\n",
    "\n",
    "            # Generic fallback if nothing matched above (rare)\n",
    "            # For some earlier branches, we already continued.\n",
    "            # If we get here, we do not have a specific check; don't flag by default.\n",
    "\n",
    "        conflicts[chunk_name] = chunk_conflicts\n",
    "        print(f\"{chunk_name} conflicts -> {chunk_conflicts}\")\n",
    "\n",
    "    state['conflicts'] = conflicts\n",
    "    return state\n",
    "\n",
    "# ============================== Step 4: Rewrite ==============================\n",
    "def rewrite_chunk(chunk_text: str, conflicts_for_chunk: List[Dict[str, str]]) -> str:\n",
    "    if not conflicts_for_chunk:\n",
    "        return chunk_text\n",
    "\n",
    "    summary = \"\\n\".join([f\"{c['subj']} {c['pred']} {c['obj']}\" for c in conflicts_for_chunk])\n",
    "    prompt = f\"\"\"\n",
    "You are a highly constrained, specialized text editor. Fix ONLY the inconsistent facts in the story chunk based on the provided triples. Return ONLY the rewritten chunk.\n",
    "\n",
    "Story chunk:\n",
    "{chunk_text}\n",
    "\n",
    "Detected inconsistencies (triples):\n",
    "{summary}\n",
    "\n",
    "Rules:\n",
    "- For hasAge: if < 18, increase minimally to >= 18; if > 110, decrease toward a plausible value (<= 110).\n",
    "- For isLocatedIn: move subjects like Eiffel_Tower to the ontology-consistent location (e.g., Paris).\n",
    "- For hasOccupation where there are too many: drop extra occupations to keep within limits.\n",
    "- For NoElectricity together with oven/baking: adjust so they are not incompatible (e.g., remove the oven use or restore electricity).\n",
    "- Change ONLY what is needed; preserve consistent content; no explanations.\n",
    "\"\"\"\n",
    "    resp = ollama.chat(model=\"llama3:latest\", messages=[{\"role\": \"user\", \"content\": prompt}])\n",
    "    # Ollama returns a dict: {\"message\":{\"role\":\"assistant\",\"content\":\"...\"}}\n",
    "    try:\n",
    "        return resp[\"message\"][\"content\"].strip()\n",
    "    except Exception:\n",
    "        # Fallback if a different shape is returned\n",
    "        return str(resp).strip()\n",
    "\n",
    "def rewrite_conflicts(state: InbetweenState) -> InbetweenState:\n",
    "    print(\"\\n=== Node: Rewrite Conflicts ===\")\n",
    "    rewritten: List[str] = []\n",
    "    for i, chunk_text in enumerate(state['chunks']):\n",
    "        name = f\"chunk_{i}\"\n",
    "        rewritten_chunk = rewrite_chunk(chunk_text, state['conflicts'].get(name, []))\n",
    "        rewritten.append(rewritten_chunk)\n",
    "        print(f\"{name}: {rewritten_chunk}\")\n",
    "    state['rewritten_chunks'] = rewritten\n",
    "    return state\n",
    "\n",
    "# ============================== Step 5: Re-verify ==============================\n",
    "def reverify_chunks(state: InbetweenState) -> InbetweenState:\n",
    "    print(\"\\n=== Node: Re-verify ===\")\n",
    "    temp_state: InbetweenState = {\n",
    "        \"story\": \" \".join(state['rewritten_chunks']),\n",
    "        \"chunks\": state['rewritten_chunks'],\n",
    "        \"ontology_summary\": \"\",\n",
    "        \"extract\": {},\n",
    "        \"conflicts\": {},\n",
    "        \"rewritten_chunks\": [],\n",
    "        \"re_verified_chunks\": [],\n",
    "        \"evaluated_chunks\": []\n",
    "    }\n",
    "    temp_state = extract(temp_state)\n",
    "    temp_state = check_conflicts(temp_state)\n",
    "\n",
    "    # keep verified chunks; also keep re-computed extract/conflicts if you want to inspect\n",
    "    state['re_verified_chunks'] = state['rewritten_chunks']\n",
    "    # Optionally store for later evaluation\n",
    "    # state['extract_after'] = temp_state['extract']\n",
    "    # state['conflicts_after'] = temp_state['conflicts']\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4b0a16ba-dd2b-4374-bdb8-030bfecd81a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================== Step 6: Assemble ==============================\n",
    "def assemble_final_story(state: InbetweenState) -> OutputState:\n",
    "    final_story = \" \".join(state['re_verified_chunks'])\n",
    "    print(\"\\n=== Node: Final Story ===\")\n",
    "    print(final_story)\n",
    "    return {\"revised_story\": final_story}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "39a91b46-8a61-43fb-8a09-2271e90788ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================== Step 7: Eval ==============================\n",
    "def flatten_extractions(extract_dict: Dict[str, List[Dict[str, str]]]) -> List[Tuple[str, Dict[str, str]]]:\n",
    "    items: List[Tuple[str, Dict[str, str]]] = []\n",
    "    for chunk_name, triples in (extract_dict or {}).items():\n",
    "        for t in (triples or []):\n",
    "            items.append((chunk_name, {\"subj\": str(t.get(\"subj\",\"\")),\n",
    "                                      \"pred\": str(t.get(\"pred\",\"\")),\n",
    "                                      \"obj\":  str(t.get(\"obj\",\"\"))}))\n",
    "    return items\n",
    "\n",
    "_PRONOUNS = {\"she\",\"he\",\"her\",\"him\",\"they\",\"them\",\"his\",\"their\"}\n",
    "_BAD_SUBJECTS = {\"and\",\"the\",\"a\",\"an\",\"city\"}\n",
    "\n",
    "def _resolve_subjects_in_story(chunks: List[str]) -> Dict[str, str]:\n",
    "    last_name = \"\"\n",
    "    proper = re.compile(r\"^[A-Z][a-z]+$\")\n",
    "    window = deque(maxlen=3)\n",
    "    for ch in chunks or []:\n",
    "        toks = re.findall(r\"[A-Za-z]+\", ch)\n",
    "        for t in toks:\n",
    "            if proper.match(t) and t.lower() != \"i\":\n",
    "                last_name = t\n",
    "                window.append(t)\n",
    "    return {\"_last\": last_name or (window[-1] if window else \"\")}\n",
    "\n",
    "def _clean_subject(subj: str, coref: Dict[str, str]) -> str:\n",
    "    s = _canon(subj)\n",
    "    if s in _PRONOUNS and coref.get(\"_last\"):\n",
    "        return _canon(coref[\"_last\"])\n",
    "    if s in _BAD_SUBJECTS:\n",
    "        return \"\"\n",
    "    return s\n",
    "\n",
    "def _is_conflict_evaluable(t: Dict[str, str]) -> bool:\n",
    "    pred = _norm_pred(t.get(\"pred\",\"\"))\n",
    "    subj = _canon(t.get(\"subj\",\"\"))\n",
    "    obj  = _norm_obj(t.get(\"obj\",\"\"))\n",
    "    if not pred or not obj or not subj:\n",
    "        return False\n",
    "    if subj in _BAD_SUBJECTS:\n",
    "        return False\n",
    "    if pred == \"haspopulation\" and obj in {\"high\",\"large\"}:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def violation_oracle(triple: Dict[str, str]) -> int:\n",
    "    subj = _canon(triple.get(\"subj\",\"\"))\n",
    "    pred = _norm_pred(triple.get(\"pred\",\"\"))\n",
    "    obj  = _norm_obj(triple.get(\"obj\",\"\"))\n",
    "\n",
    "    if pred == \"hasage\":\n",
    "        age_val = _to_int_maybe(triple.get(\"obj\",\"\"))\n",
    "        return 1 if (age_val is None or age_val < 18) else 0\n",
    "    if pred == \"islocatedin\" and subj in _EIFFEL_ALIASES:\n",
    "        return 1 if obj != \"paris\" else 0\n",
    "    return 0\n",
    "\n",
    "def collect_labels(state: InbetweenState) -> Tuple[List[int], List[int], List[Tuple[str, Dict[str, str]]]]:\n",
    "    flat = flatten_extractions(state.get(\"extract\", {}))\n",
    "    coref_hint = _resolve_subjects_in_story(state.get(\"chunks\", []))\n",
    "\n",
    "    conflict_set = set()\n",
    "    for ch, triples in (state.get(\"conflicts\", {}) or {}).items():\n",
    "        for t in (triples or []):\n",
    "            if not _is_conflict_evaluable(t):\n",
    "                continue\n",
    "            key = (\n",
    "                _canon(ch),\n",
    "                _clean_subject(t.get(\"subj\",\"\"), coref_hint),\n",
    "                _norm_pred(t.get(\"pred\",\"\")),\n",
    "                _norm_obj(t.get(\"obj\",\"\")),\n",
    "            )\n",
    "            if key[1] and key[2]:\n",
    "                conflict_set.add(key)\n",
    "\n",
    "    occ_seen: Dict[str, int] = defaultdict(int)\n",
    "    city_pop: Dict[str, bool] = defaultdict(bool)\n",
    "    city_quiet: Dict[str, bool] = defaultdict(bool)\n",
    "    has_no_elec = False\n",
    "    used_oven   = False\n",
    "    jan_reserved = False\n",
    "    jan_social   = False\n",
    "\n",
    "    normalized_flat: List[Tuple[str, Dict[str,str]]] = []\n",
    "    for chunk_name, t in flat:\n",
    "        subj = _clean_subject(t.get(\"subj\",\"\"), coref_hint)\n",
    "        pred = _norm_pred(t.get(\"pred\",\"\"))\n",
    "        obj  = _norm_obj(t.get(\"obj\",\"\"))\n",
    "        normalized_flat.append((chunk_name, {\"subj\": subj, \"pred\": pred, \"obj\": obj}))\n",
    "\n",
    "        if pred == \"haspopulation\" and obj in {\"high\",\"large\"}:\n",
    "            city_pop[subj] = True\n",
    "        if pred == \"description\" and any(k in obj for k in [\"quiet\",\"empty\",\"calm\"]):\n",
    "            city_quiet[subj] = True\n",
    "        if pred == \"hastrait\" and subj == \"jan\":\n",
    "            if obj == \"reserved\": jan_reserved = True\n",
    "            if obj == \"social\":   jan_social = True\n",
    "        if pred == \"requirestool\" and obj == \"oven\":\n",
    "            used_oven = True\n",
    "        if pred == \"hasresourcestatus\" and obj == \"noelectricity\":\n",
    "            has_no_elec = True\n",
    "\n",
    "    y_true: List[int] = []\n",
    "    y_pred: List[int] = []\n",
    "    aligned: List[Tuple[str, Dict[str, str]]] = []\n",
    "\n",
    "    for chunk_name, t in normalized_flat:\n",
    "        subj, pred, obj = t[\"subj\"], t[\"pred\"], t[\"obj\"]\n",
    "        gold = violation_oracle(t)\n",
    "\n",
    "        if pred == \"hasoccupation\" and subj:\n",
    "            occ_seen[subj] += 1\n",
    "            if occ_seen[subj] > 1:\n",
    "                gold = 1\n",
    "        if pred in {\"haspopulation\",\"description\"} and subj and city_pop.get(subj) and city_quiet.get(subj):\n",
    "            gold = 1\n",
    "        if subj == \"jan\" and pred == \"hastrait\" and (jan_reserved and jan_social):\n",
    "            gold = 1\n",
    "        if used_oven and has_no_elec and pred in {\"hasresourcestatus\",\"requirestool\"}:\n",
    "            gold = 1\n",
    "\n",
    "        pred_label = 1 if ((_canon(chunk_name), subj, pred, obj) in conflict_set) else 0\n",
    "\n",
    "        y_true.append(gold)\n",
    "        y_pred.append(pred_label)\n",
    "        aligned.append((chunk_name, {\"subj\": subj, \"pred\": pred, \"obj\": obj}))\n",
    "\n",
    "    return y_true, y_pred, aligned\n",
    "\n",
    "def compute_metrics(y_true: List[int], y_pred: List[int]) -> Dict[str, Any]:\n",
    "    n = min(len(y_true), len(y_pred))\n",
    "    if n == 0:\n",
    "        return Metrics(tp=0, tn=0, fp=0, fn=0, precision=0.0, recall=0.0, f1=0.0, accuracy=0.0).__dict__\n",
    "    yt, yp = y_true[:n], y_pred[:n]\n",
    "    tp = sum(1 for a,b in zip(yt, yp) if a==1 and b==1)\n",
    "    tn = sum(1 for a,b in zip(yt, yp) if a==0 and b==0)\n",
    "    fp = sum(1 for a,b in zip(yt, yp) if a==0 and b==1)\n",
    "    fn = sum(1 for a,b in zip(yt, yp) if a==1 and b==0)\n",
    "    precision = _safe_ratio(tp, tp+fp)\n",
    "    recall    = _safe_ratio(tp, tp+fn)\n",
    "    f1        = _safe_ratio(2*precision*recall, precision+recall) if (precision or recall) else 0.0\n",
    "    accuracy  = _safe_ratio(tp+tn, tp+tn+fp+fn)\n",
    "    return Metrics(tp=tp, tn=tn, fp=fp, fn=fn,\n",
    "                   precision=precision, recall=recall, f1=f1, accuracy=accuracy).__dict__\n",
    "\n",
    "def reputation_scores(aligned_records: List[Tuple[str, Dict[str, str]]], y_true: List[int]) -> Dict[str, Any]:\n",
    "    total = len(y_true)\n",
    "    overall = _safe_ratio(sum(1 for v in y_true if v == 0), total) if total else 1.0\n",
    "    by_chunk_gold: Dict[str, List[int]] = defaultdict(list)\n",
    "    by_subject_gold: Dict[str, List[int]] = defaultdict(list)\n",
    "    for (chunk_name, t), gold in zip(aligned_records, y_true):\n",
    "        by_chunk_gold[chunk_name].append(gold)\n",
    "        by_subject_gold[t.get(\"subj\",\"\")].append(gold)\n",
    "    chunk_rep = {ch: _safe_ratio(vals.count(0), len(vals)) for ch, vals in by_chunk_gold.items() if vals}\n",
    "    subj_rep  = {sj: _safe_ratio(vals.count(0), len(vals)) for sj, vals in by_subject_gold.items() if vals}\n",
    "    return {\"overall\": overall, \"by_chunk\": chunk_rep, \"by_subject\": subj_rep}\n",
    "\n",
    "def recompute_on_text(chunks: List[str]) -> Tuple[Dict[str, List[Dict[str, str]]], Dict[str, List[Dict[str, str]]]]:\n",
    "    temp_state: InbetweenState = {\n",
    "        \"story\": \" \".join(chunks or []),\n",
    "        \"chunks\": chunks or [],\n",
    "        \"ontology_summary\": \"\",\n",
    "        \"extract\": {},\n",
    "        \"conflicts\": {},\n",
    "        \"rewritten_chunks\": [],\n",
    "        \"re_verified_chunks\": [],\n",
    "        \"evaluated_chunks\": []\n",
    "    }\n",
    "    temp_state = extract(temp_state)\n",
    "    temp_state = check_conflicts(temp_state)\n",
    "    return temp_state.get(\"extract\", {}), temp_state.get(\"conflicts\", {})\n",
    "\n",
    "def rows_for_export(aligned: List[Tuple[str, Dict[str, str]]],\n",
    "                    y_true: List[int], y_pred: List[int]) -> List[Dict[str, Any]]:\n",
    "    rows: List[Dict[str, Any]] = []\n",
    "    n = min(len(aligned), len(y_true), len(y_pred))\n",
    "    for i in range(n):\n",
    "        chunk_name, t = aligned[i]\n",
    "        gold, pred = y_true[i], y_pred[i]\n",
    "        rows.append({\n",
    "            \"chunk\": chunk_name,\n",
    "            \"subject\": t.get(\"subj\",\"\"),\n",
    "            \"predicate\": t.get(\"pred\",\"\"),\n",
    "            \"object\": t.get(\"obj\",\"\"),\n",
    "            \"gold_violation\": gold,\n",
    "            \"pred_violation\": pred,\n",
    "            \"label\": _label_of(gold, pred)\n",
    "        })\n",
    "    return rows\n",
    "\n",
    "def run_one_story(story_text: str) -> Dict[str, Any]:\n",
    "    state = chunk({\"story\": story_text})\n",
    "    state = extract(state)\n",
    "    state = check_conflicts(state)\n",
    "\n",
    "    y_true_b, y_pred_b, aligned_b = collect_labels(state)\n",
    "    mb = compute_metrics(y_true_b, y_pred_b)\n",
    "    vb = sum(y_true_b)\n",
    "\n",
    "    state = rewrite_conflicts(state)\n",
    "    state = reverify_chunks(state)\n",
    "\n",
    "    ex_after, conf_after = recompute_on_text(state.get(\"re_verified_chunks\", []))\n",
    "    temp_after: InbetweenState = {\n",
    "        \"story\": \" \".join(state.get(\"re_verified_chunks\", [])),\n",
    "        \"chunks\": state.get(\"re_verified_chunks\", []),\n",
    "        \"ontology_summary\": \"\",\n",
    "        \"extract\": ex_after,\n",
    "        \"conflicts\": conf_after,\n",
    "        \"rewritten_chunks\": [],\n",
    "        \"re_verified_chunks\": [],\n",
    "        \"evaluated_chunks\": []\n",
    "    }\n",
    "    y_true_a, y_pred_a, aligned_a = collect_labels(temp_after)\n",
    "    ma = compute_metrics(y_true_a, y_pred_a)\n",
    "    va = sum(y_true_a)\n",
    "\n",
    "    return {\"before\": mb, \"after\": ma, \"viol_before\": vb, \"viol_after\": va}\n",
    "\n",
    "def micro_sum(metrics_list: Iterable[Dict[str, Any]]) -> Dict[str, Any]:\n",
    "    tp = sum(int(m.get(\"tp\", 0)) for m in metrics_list)\n",
    "    fp = sum(int(m.get(\"fp\", 0)) for m in metrics_list)\n",
    "    fn = sum(int(m.get(\"fn\", 0)) for m in metrics_list)\n",
    "    tn = sum(int(m.get(\"tn\", 0)) for m in metrics_list)\n",
    "    precision = _safe_ratio(tp, tp+fp)\n",
    "    recall    = _safe_ratio(tp, tp+fn)\n",
    "    f1        = _safe_ratio(2*precision*recall, precision+recall) if (precision or recall) else 0.0\n",
    "    accuracy  = _safe_ratio(tp+tn, tp+tn+fp+fn)\n",
    "    return Metrics(tp=tp, fp=fp, fn=fn, tn=tn,\n",
    "                   precision=precision, recall=recall, f1=f1, accuracy=accuracy).__dict__\n",
    "\n",
    "def run_suite(stories: List[str]):\n",
    "    runs = [run_one_story(s) for s in (stories or [])]\n",
    "    micro_before = micro_sum((r[\"before\"] for r in runs))\n",
    "    micro_after  = micro_sum((r[\"after\"]  for r in runs))\n",
    "    viol_before  = sum(int(r[\"viol_before\"]) for r in runs) or 0\n",
    "    viol_after   = sum(int(r[\"viol_after\"])  for r in runs) or 0\n",
    "    resolution   = _safe_ratio((viol_before - viol_after), viol_before) if viol_before else 0.0\n",
    "    print(\"\\n=== MICRO-AVERAGED (across stories) ===\")\n",
    "    print(\"Before:\", micro_before)\n",
    "    print(\"After:\", micro_after)\n",
    "    print(f\"Violations (gold): {viol_before} → {viol_after}  (Resolution: {resolution:.3f})\")\n",
    "    return runs, micro_before, micro_after, resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "aa226720-1acc-4091-9d91-234b2b425016",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _print_reputation(title: str, rep: Dict[str, Any], top_k: int = 5) -> None:\n",
    "    \"\"\"\n",
    "    Pretty-print reputation scores.\n",
    "    rep = {\"overall\": float, \"by_chunk\": {chunk: score}, \"by_subject\": {subject: score}}\n",
    "    Higher is better (1.0 means no gold violations).\n",
    "    \"\"\"\n",
    "    print(f\"\\n=== REPUTATION — {title} ===\")\n",
    "    print(f\"Overall: {rep.get('overall', 0.0):.3f}\")\n",
    "\n",
    "    by_chunk = rep.get(\"by_chunk\", {}) or {}\n",
    "    by_subject = rep.get(\"by_subject\", {}) or {}\n",
    "\n",
    "    if by_chunk:\n",
    "        worst_chunks = sorted(by_chunk.items(), key=lambda kv: kv[1])[:top_k]\n",
    "        best_chunks  = sorted(by_chunk.items(), key=lambda kv: kv[1], reverse=True)[:top_k]\n",
    "        print(\"  Worst chunks (↓): \" + \", \".join([f\"{k}:{v:.2f}\" for k, v in worst_chunks]))\n",
    "        print(\"  Best  chunks (↑): \"  + \", \".join([f\"{k}:{v:.2f}\" for k, v in best_chunks]))\n",
    "    else:\n",
    "        print(\"  (no chunk-level records)\")\n",
    "\n",
    "    if by_subject:\n",
    "        worst_subj = sorted(by_subject.items(), key=lambda kv: kv[1])[:top_k]\n",
    "        best_subj  = sorted(by_subject.items(), key=lambda kv: kv[1], reverse=True)[:top_k]\n",
    "        print(\"  Worst subjects (↓): \" + \", \".join([f\"{(k or '<empty>')}:{v:.2f}\" for k, v in worst_subj]))\n",
    "        print(\"  Best  subjects (↑): \"  + \", \".join([f\"{(k or '<empty>')}:{v:.2f}\" for k, v in best_subj]))\n",
    "    else:\n",
    "        print(\"  (no subject-level records)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "daa40ac0-9c18-4adb-bc41-7a519e140979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "#############################\n",
      "### RUNNING SCENARIO 1 ###\n",
      "#############################\n",
      "Amelia is one of France's most famous lawyers. She is 17 years old and recently married her husband Adam, who is 25.\n",
      "\n",
      "\n",
      "=== Node: Chunk ===\n",
      "[\"Amelia is one of France's most famous lawyers.\", 'She is 17 years old and recently married her husband Adam, who is 25.']\n",
      "\n",
      "=== Node: Extract Triples ===\n",
      "chunk_0 -> []\n",
      "chunk_1 -> [{'subj': 'She', 'pred': 'hasAge', 'obj': '17'}, {'subj': 'She', 'pred': 'isMarriedTo', 'obj': 'Adam'}]\n",
      "\n",
      "=== Node: Check Conflicts with SPARQL ===\n",
      "chunk_0 conflicts -> []\n",
      "chunk_1 conflicts -> [{'subj': 'She', 'pred': 'hasAge', 'obj': '17'}]\n",
      "\n",
      "=== METRICS — BEFORE REWRITE ===\n",
      "{'tp': 1, 'tn': 1, 'fp': 0, 'fn': 0, 'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'accuracy': 1.0}\n",
      "Gold violations (sum of y_true): 1\n",
      "\n",
      "=== REPUTATION — BEFORE ===\n",
      "Overall: 0.500\n",
      "  Worst chunks (↓): chunk_1:0.50\n",
      "  Best  chunks (↑): chunk_1:0.50\n",
      "  Worst subjects (↓): adam:0.50\n",
      "  Best  subjects (↑): adam:0.50\n",
      "\n",
      "=== Node: Rewrite Conflicts ===\n",
      "chunk_0: Amelia is one of France's most famous lawyers.\n",
      "chunk_1: Story chunk:\n",
      "She is 18 years old and recently married her husband Adam, who is 25.\n",
      "\n",
      "=== Node: Re-verify ===\n",
      "\n",
      "=== Node: Extract Triples ===\n",
      "chunk_0 -> []\n",
      "chunk_1 -> [{'subj': 'Story', 'pred': 'hasAge', 'obj': '18'}, {'subj': 'Story', 'pred': 'isMarriedTo', 'obj': 'Adam'}]\n",
      "\n",
      "=== Node: Check Conflicts with SPARQL ===\n",
      "chunk_0 conflicts -> []\n",
      "chunk_1 conflicts -> []\n",
      "\n",
      "=== Node: Extract Triples ===\n",
      "chunk_0 -> []\n",
      "chunk_1 -> [{'subj': 'Story', 'pred': 'hasAge', 'obj': '18'}, {'subj': 'Story', 'pred': 'isMarriedTo', 'obj': 'Adam'}]\n",
      "\n",
      "=== Node: Check Conflicts with SPARQL ===\n",
      "chunk_0 conflicts -> []\n",
      "chunk_1 conflicts -> []\n",
      "\n",
      "=== METRICS — AFTER REWRITE ===\n",
      "{'tp': 0, 'tn': 2, 'fp': 0, 'fn': 0, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'accuracy': 1.0}\n",
      "Gold violations (sum of y_true): 0\n",
      "\n",
      "=== REPUTATION — AFTER ===\n",
      "Overall: 1.000\n",
      "  Worst chunks (↓): chunk_1:1.00\n",
      "  Best  chunks (↑): chunk_1:1.00\n",
      "  Worst subjects (↓): story:1.00\n",
      "  Best  subjects (↑): story:1.00\n",
      "\n",
      "=== SUMMARY ===\n",
      "Resolution: 1.000  (gold violations 1 → 0)\n",
      "\n",
      "=== Node: Final Story ===\n",
      "Amelia is one of France's most famous lawyers. Story chunk:\n",
      "She is 18 years old and recently married her husband Adam, who is 25.\n",
      "\n",
      "=== FINAL OUTPUT ===\n",
      "Amelia is one of France's most famous lawyers. Story chunk:\n",
      "She is 18 years old and recently married her husband Adam, who is 25.\n",
      "\n",
      "\n",
      "#############################\n",
      "### RUNNING SCENARIO 2 ###\n",
      "#############################\n",
      "They live together in Paris, a quiet city without much hustle and bustle since the city has a large population.\n",
      "The city is located on flat land, so there are no mountains.\n",
      "\n",
      "\n",
      "=== Node: Chunk ===\n",
      "['They live together in Paris, a quiet city without much hustle and bustle since the city has a large population.', 'The city is located on flat land, so there are no mountains.']\n",
      "\n",
      "=== Node: Extract Triples ===\n",
      "chunk_0 -> [{'subj': 'quiet_city_without_much_hustle_and_bustle_since_the_city', 'pred': 'hasPopulation', 'obj': 'large'}]\n",
      "chunk_1 -> []\n",
      "\n",
      "=== Node: Check Conflicts with SPARQL ===\n",
      "chunk_0 conflicts -> []\n",
      "chunk_1 conflicts -> []\n",
      "\n",
      "=== METRICS — BEFORE REWRITE ===\n",
      "{'tp': 0, 'tn': 1, 'fp': 0, 'fn': 0, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'accuracy': 1.0}\n",
      "Gold violations (sum of y_true): 0\n",
      "\n",
      "=== REPUTATION — BEFORE ===\n",
      "Overall: 1.000\n",
      "  Worst chunks (↓): chunk_0:1.00\n",
      "  Best  chunks (↑): chunk_0:1.00\n",
      "  Worst subjects (↓): quiet_city_without_much_hustle_and_bustle_since_the_city:1.00\n",
      "  Best  subjects (↑): quiet_city_without_much_hustle_and_bustle_since_the_city:1.00\n",
      "\n",
      "=== Node: Rewrite Conflicts ===\n",
      "chunk_0: They live together in Paris, a quiet city without much hustle and bustle since the city has a large population.\n",
      "chunk_1: The city is located on flat land, so there are no mountains.\n",
      "\n",
      "=== Node: Re-verify ===\n",
      "\n",
      "=== Node: Extract Triples ===\n",
      "chunk_0 -> [{'subj': 'quiet_city_without_much_hustle_and_bustle_since_the_city', 'pred': 'hasPopulation', 'obj': 'large'}]\n",
      "chunk_1 -> []\n",
      "\n",
      "=== Node: Check Conflicts with SPARQL ===\n",
      "chunk_0 conflicts -> []\n",
      "chunk_1 conflicts -> []\n",
      "\n",
      "=== Node: Extract Triples ===\n",
      "chunk_0 -> [{'subj': 'quiet_city_without_much_hustle_and_bustle_since_the_city', 'pred': 'hasPopulation', 'obj': 'large'}]\n",
      "chunk_1 -> []\n",
      "\n",
      "=== Node: Check Conflicts with SPARQL ===\n",
      "chunk_0 conflicts -> []\n",
      "chunk_1 conflicts -> []\n",
      "\n",
      "=== METRICS — AFTER REWRITE ===\n",
      "{'tp': 0, 'tn': 1, 'fp': 0, 'fn': 0, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'accuracy': 1.0}\n",
      "Gold violations (sum of y_true): 0\n",
      "\n",
      "=== REPUTATION — AFTER ===\n",
      "Overall: 1.000\n",
      "  Worst chunks (↓): chunk_0:1.00\n",
      "  Best  chunks (↑): chunk_0:1.00\n",
      "  Worst subjects (↓): quiet_city_without_much_hustle_and_bustle_since_the_city:1.00\n",
      "  Best  subjects (↑): quiet_city_without_much_hustle_and_bustle_since_the_city:1.00\n",
      "\n",
      "=== SUMMARY ===\n",
      "Resolution: 0.000  (gold violations 0 → 0)\n",
      "\n",
      "=== Node: Final Story ===\n",
      "They live together in Paris, a quiet city without much hustle and bustle since the city has a large population. The city is located on flat land, so there are no mountains.\n",
      "\n",
      "=== FINAL OUTPUT ===\n",
      "They live together in Paris, a quiet city without much hustle and bustle since the city has a large population. The city is located on flat land, so there are no mountains.\n",
      "\n",
      "\n",
      "#############################\n",
      "### RUNNING SCENARIO 3 ###\n",
      "#############################\n",
      "The Eiffel Tower is located in Italy.\n",
      "\n",
      "\n",
      "=== Node: Chunk ===\n",
      "['The Eiffel Tower is located in Italy.']\n",
      "\n",
      "=== Node: Extract Triples ===\n",
      "chunk_0 -> [{'subj': 'Eiffel_Tower', 'pred': 'isLocatedIn', 'obj': 'Italy'}]\n",
      "\n",
      "=== Node: Check Conflicts with SPARQL ===\n",
      "chunk_0 conflicts -> [{'subj': 'Eiffel_Tower', 'pred': 'isLocatedIn', 'obj': 'Italy'}]\n",
      "\n",
      "=== METRICS — BEFORE REWRITE ===\n",
      "{'tp': 1, 'tn': 0, 'fp': 0, 'fn': 0, 'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'accuracy': 1.0}\n",
      "Gold violations (sum of y_true): 1\n",
      "\n",
      "=== REPUTATION — BEFORE ===\n",
      "Overall: 0.000\n",
      "  Worst chunks (↓): chunk_0:0.00\n",
      "  Best  chunks (↑): chunk_0:0.00\n",
      "  Worst subjects (↓): eiffel_tower:0.00\n",
      "  Best  subjects (↑): eiffel_tower:0.00\n",
      "\n",
      "=== Node: Rewrite Conflicts ===\n",
      "chunk_0: Here is the rewritten chunk:\n",
      "\n",
      "The Eiffel Tower is located in Paris.\n",
      "\n",
      "=== Node: Re-verify ===\n",
      "\n",
      "=== Node: Extract Triples ===\n",
      "chunk_0 -> [{'subj': 'Eiffel_Tower', 'pred': 'isLocatedIn', 'obj': 'Paris'}]\n",
      "\n",
      "=== Node: Check Conflicts with SPARQL ===\n",
      "chunk_0 conflicts -> []\n",
      "\n",
      "=== Node: Extract Triples ===\n",
      "chunk_0 -> [{'subj': 'Eiffel_Tower', 'pred': 'isLocatedIn', 'obj': 'Paris'}]\n",
      "\n",
      "=== Node: Check Conflicts with SPARQL ===\n",
      "chunk_0 conflicts -> []\n",
      "\n",
      "=== METRICS — AFTER REWRITE ===\n",
      "{'tp': 0, 'tn': 1, 'fp': 0, 'fn': 0, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'accuracy': 1.0}\n",
      "Gold violations (sum of y_true): 0\n",
      "\n",
      "=== REPUTATION — AFTER ===\n",
      "Overall: 1.000\n",
      "  Worst chunks (↓): chunk_0:1.00\n",
      "  Best  chunks (↑): chunk_0:1.00\n",
      "  Worst subjects (↓): eiffel_tower:1.00\n",
      "  Best  subjects (↑): eiffel_tower:1.00\n",
      "\n",
      "=== SUMMARY ===\n",
      "Resolution: 1.000  (gold violations 1 → 0)\n",
      "\n",
      "=== Node: Final Story ===\n",
      "Here is the rewritten chunk:\n",
      "\n",
      "The Eiffel Tower is located in Paris.\n",
      "\n",
      "=== FINAL OUTPUT ===\n",
      "Here is the rewritten chunk:\n",
      "\n",
      "The Eiffel Tower is located in Paris.\n",
      "\n",
      "\n",
      "#############################\n",
      "### RUNNING SCENARIO 4 ###\n",
      "#############################\n",
      "Her husband Adam is a baker and a merchant. He makes various types of French pastries, including macarons, but also baguettes and croissants.\n",
      "Unfortunately, Amelia cannot eat many sweets because she is allergic to the filling which contains dairy.\n",
      "\n",
      "\n",
      "=== Node: Chunk ===\n",
      "['Her husband Adam is a baker and a merchant.', 'He makes various types of French pastries, including macarons, but also baguettes and croissants.', 'Unfortunately, Amelia cannot eat many sweets because she is allergic to the filling which contains dairy.']\n",
      "\n",
      "=== Node: Extract Triples ===\n",
      "chunk_0 -> [{'subj': 'Her', 'pred': 'hasOccupation', 'obj': 'baker and a merchant'}]\n",
      "chunk_1 -> []\n",
      "chunk_2 -> []\n",
      "\n",
      "=== Node: Check Conflicts with SPARQL ===\n",
      "chunk_0 conflicts -> []\n",
      "chunk_1 conflicts -> []\n",
      "chunk_2 conflicts -> []\n",
      "\n",
      "=== METRICS — BEFORE REWRITE ===\n",
      "{'tp': 0, 'tn': 1, 'fp': 0, 'fn': 0, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'accuracy': 1.0}\n",
      "Gold violations (sum of y_true): 0\n",
      "\n",
      "=== REPUTATION — BEFORE ===\n",
      "Overall: 1.000\n",
      "  Worst chunks (↓): chunk_0:1.00\n",
      "  Best  chunks (↑): chunk_0:1.00\n",
      "  Worst subjects (↓): amelia:1.00\n",
      "  Best  subjects (↑): amelia:1.00\n",
      "\n",
      "=== Node: Rewrite Conflicts ===\n",
      "chunk_0: Her husband Adam is a baker and a merchant.\n",
      "chunk_1: He makes various types of French pastries, including macarons, but also baguettes and croissants.\n",
      "chunk_2: Unfortunately, Amelia cannot eat many sweets because she is allergic to the filling which contains dairy.\n",
      "\n",
      "=== Node: Re-verify ===\n",
      "\n",
      "=== Node: Extract Triples ===\n",
      "chunk_0 -> [{'subj': 'Her', 'pred': 'hasOccupation', 'obj': 'baker and a merchant'}]\n",
      "chunk_1 -> []\n",
      "chunk_2 -> []\n",
      "\n",
      "=== Node: Check Conflicts with SPARQL ===\n",
      "chunk_0 conflicts -> []\n",
      "chunk_1 conflicts -> []\n",
      "chunk_2 conflicts -> []\n",
      "\n",
      "=== Node: Extract Triples ===\n",
      "chunk_0 -> [{'subj': 'Her', 'pred': 'hasOccupation', 'obj': 'baker and a merchant'}]\n",
      "chunk_1 -> []\n",
      "chunk_2 -> []\n",
      "\n",
      "=== Node: Check Conflicts with SPARQL ===\n",
      "chunk_0 conflicts -> []\n",
      "chunk_1 conflicts -> []\n",
      "chunk_2 conflicts -> []\n",
      "\n",
      "=== METRICS — AFTER REWRITE ===\n",
      "{'tp': 0, 'tn': 1, 'fp': 0, 'fn': 0, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'accuracy': 1.0}\n",
      "Gold violations (sum of y_true): 0\n",
      "\n",
      "=== REPUTATION — AFTER ===\n",
      "Overall: 1.000\n",
      "  Worst chunks (↓): chunk_0:1.00\n",
      "  Best  chunks (↑): chunk_0:1.00\n",
      "  Worst subjects (↓): amelia:1.00\n",
      "  Best  subjects (↑): amelia:1.00\n",
      "\n",
      "=== SUMMARY ===\n",
      "Resolution: 0.000  (gold violations 0 → 0)\n",
      "\n",
      "=== Node: Final Story ===\n",
      "Her husband Adam is a baker and a merchant. He makes various types of French pastries, including macarons, but also baguettes and croissants. Unfortunately, Amelia cannot eat many sweets because she is allergic to the filling which contains dairy.\n",
      "\n",
      "=== FINAL OUTPUT ===\n",
      "Her husband Adam is a baker and a merchant. He makes various types of French pastries, including macarons, but also baguettes and croissants. Unfortunately, Amelia cannot eat many sweets because she is allergic to the filling which contains dairy.\n",
      "\n",
      "\n",
      "#############################\n",
      "### RUNNING SCENARIO 5 ###\n",
      "#############################\n",
      "Amelia's husband describes her as a good hearted and self serving person who cares about the well-being of people.\n",
      "\n",
      "\n",
      "=== Node: Chunk ===\n",
      "[\"Amelia's husband describes her as a good hearted and self serving person who cares about the well-being of people.\"]\n",
      "\n",
      "=== Node: Extract Triples ===\n",
      "chunk_0 -> [{'subj': 'Amelia', 'pred': 'hasTrait', 'obj': 'Good_Hearted_And_Self_Serving'}]\n",
      "\n",
      "=== Node: Check Conflicts with SPARQL ===\n",
      "chunk_0 conflicts -> [{'subj': 'Amelia', 'pred': 'hasTrait', 'obj': 'Good_Hearted_And_Self_Serving'}]\n",
      "\n",
      "=== METRICS — BEFORE REWRITE ===\n",
      "{'tp': 0, 'tn': 0, 'fp': 1, 'fn': 0, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'accuracy': 0.0}\n",
      "Gold violations (sum of y_true): 0\n",
      "\n",
      "=== REPUTATION — BEFORE ===\n",
      "Overall: 1.000\n",
      "  Worst chunks (↓): chunk_0:1.00\n",
      "  Best  chunks (↑): chunk_0:1.00\n",
      "  Worst subjects (↓): amelia:1.00\n",
      "  Best  subjects (↑): amelia:1.00\n",
      "\n",
      "=== Node: Rewrite Conflicts ===\n",
      "chunk_0: Here is the rewritten story chunk:\n",
      "\n",
      "Amelia has a good-hearted and self-serving trait.\n",
      "\n",
      "Note that there were no inconsistencies to fix, as the original story chunk was already free of factual errors. The provided triples did not indicate any issues with age, location, occupation, or electricity usage. Therefore, the rewritten chunk remains identical to the original.\n",
      "\n",
      "=== Node: Re-verify ===\n",
      "\n",
      "=== Node: Extract Triples ===\n",
      "chunk_0 -> []\n",
      "\n",
      "=== Node: Check Conflicts with SPARQL ===\n",
      "chunk_0 conflicts -> []\n",
      "\n",
      "=== Node: Extract Triples ===\n",
      "chunk_0 -> []\n",
      "\n",
      "=== Node: Check Conflicts with SPARQL ===\n",
      "chunk_0 conflicts -> []\n",
      "\n",
      "=== METRICS — AFTER REWRITE ===\n",
      "{'tp': 0, 'tn': 0, 'fp': 0, 'fn': 0, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'accuracy': 0.0}\n",
      "Gold violations (sum of y_true): 0\n",
      "\n",
      "=== REPUTATION — AFTER ===\n",
      "Overall: 1.000\n",
      "  (no chunk-level records)\n",
      "  (no subject-level records)\n",
      "\n",
      "=== SUMMARY ===\n",
      "Resolution: 0.000  (gold violations 0 → 0)\n",
      "\n",
      "=== Node: Final Story ===\n",
      "Here is the rewritten story chunk:\n",
      "\n",
      "Amelia has a good-hearted and self-serving trait.\n",
      "\n",
      "Note that there were no inconsistencies to fix, as the original story chunk was already free of factual errors. The provided triples did not indicate any issues with age, location, occupation, or electricity usage. Therefore, the rewritten chunk remains identical to the original.\n",
      "\n",
      "=== FINAL OUTPUT ===\n",
      "Here is the rewritten story chunk:\n",
      "\n",
      "Amelia has a good-hearted and self-serving trait.\n",
      "\n",
      "Note that there were no inconsistencies to fix, as the original story chunk was already free of factual errors. The provided triples did not indicate any issues with age, location, occupation, or electricity usage. Therefore, the rewritten chunk remains identical to the original.\n",
      "\n",
      "\n",
      "#############################\n",
      "### RUNNING SCENARIO 6 ###\n",
      "#############################\n",
      "It was the day that there was no electricity in Paris. Amelia went to the bakery where Adam worked.\n",
      "When Amelia came in, she immediately bought two croissants which were made in the oven.\n",
      "\n",
      "\n",
      "=== Node: Chunk ===\n",
      "['It was the day that there was no electricity in Paris.', 'Amelia went to the bakery where Adam worked.', 'When Amelia came in, she immediately bought two croissants which were made in the oven.']\n",
      "\n",
      "=== Node: Extract Triples ===\n",
      "chunk_0 -> [{'subj': 'Paris', 'pred': 'hasResourceStatus', 'obj': 'NoElectricity'}]\n",
      "chunk_1 -> []\n",
      "chunk_2 -> [{'subj': 'Baking', 'pred': 'requiresTool', 'obj': 'Oven'}]\n",
      "\n",
      "=== Node: Check Conflicts with SPARQL ===\n",
      "chunk_0 conflicts -> [{'subj': 'Paris', 'pred': 'hasResourceStatus', 'obj': 'NoElectricity'}]\n",
      "chunk_1 conflicts -> []\n",
      "chunk_2 conflicts -> [{'subj': 'Baking', 'pred': 'requiresTool', 'obj': 'Oven'}]\n",
      "\n",
      "=== METRICS — BEFORE REWRITE ===\n",
      "{'tp': 2, 'tn': 0, 'fp': 0, 'fn': 0, 'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'accuracy': 1.0}\n",
      "Gold violations (sum of y_true): 2\n",
      "\n",
      "=== REPUTATION — BEFORE ===\n",
      "Overall: 0.000\n",
      "  Worst chunks (↓): chunk_0:0.00, chunk_2:0.00\n",
      "  Best  chunks (↑): chunk_0:0.00, chunk_2:0.00\n",
      "  Worst subjects (↓): paris:0.00, baking:0.00\n",
      "  Best  subjects (↑): paris:0.00, baking:0.00\n",
      "\n",
      "=== Node: Rewrite Conflicts ===\n",
      "chunk_0: Here is the rewritten chunk:\n",
      "\n",
      "It was the day when Paris had no electricity.\n",
      "\n",
      "Note: The original sentence mentioned \"there was no electricity in Paris\", but since we only have a fact about Paris having NoElectricity, we simplified the sentence to reflect this.\n",
      "chunk_1: Amelia went to the bakery where Adam worked.\n",
      "chunk_2: Here is the rewritten story chunk based on the provided triples:\n",
      "\n",
      "When Amelia came in, she immediately bought two croissants which were made using a baking tool.\n",
      "\n",
      "Note: I removed \"in the oven\" as it was inconsistent with the fact that baking requires a tool. The rest of the original content remains unchanged.\n",
      "\n",
      "=== Node: Re-verify ===\n",
      "\n",
      "=== Node: Extract Triples ===\n",
      "chunk_0 -> [{'subj': 'Paris', 'pred': 'hasResourceStatus', 'obj': 'NoElectricity'}]\n",
      "chunk_1 -> []\n",
      "chunk_2 -> []\n",
      "\n",
      "=== Node: Check Conflicts with SPARQL ===\n",
      "chunk_0 conflicts -> [{'subj': 'Paris', 'pred': 'hasResourceStatus', 'obj': 'NoElectricity'}]\n",
      "chunk_1 conflicts -> []\n",
      "chunk_2 conflicts -> []\n",
      "\n",
      "=== Node: Extract Triples ===\n",
      "chunk_0 -> [{'subj': 'Paris', 'pred': 'hasResourceStatus', 'obj': 'NoElectricity'}]\n",
      "chunk_1 -> []\n",
      "chunk_2 -> []\n",
      "\n",
      "=== Node: Check Conflicts with SPARQL ===\n",
      "chunk_0 conflicts -> [{'subj': 'Paris', 'pred': 'hasResourceStatus', 'obj': 'NoElectricity'}]\n",
      "chunk_1 conflicts -> []\n",
      "chunk_2 conflicts -> []\n",
      "\n",
      "=== METRICS — AFTER REWRITE ===\n",
      "{'tp': 0, 'tn': 0, 'fp': 1, 'fn': 0, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'accuracy': 0.0}\n",
      "Gold violations (sum of y_true): 0\n",
      "\n",
      "=== REPUTATION — AFTER ===\n",
      "Overall: 1.000\n",
      "  Worst chunks (↓): chunk_0:1.00\n",
      "  Best  chunks (↑): chunk_0:1.00\n",
      "  Worst subjects (↓): paris:1.00\n",
      "  Best  subjects (↑): paris:1.00\n",
      "\n",
      "=== SUMMARY ===\n",
      "Resolution: 1.000  (gold violations 2 → 0)\n",
      "\n",
      "=== Node: Final Story ===\n",
      "Here is the rewritten chunk:\n",
      "\n",
      "It was the day when Paris had no electricity.\n",
      "\n",
      "Note: The original sentence mentioned \"there was no electricity in Paris\", but since we only have a fact about Paris having NoElectricity, we simplified the sentence to reflect this. Amelia went to the bakery where Adam worked. Here is the rewritten story chunk based on the provided triples:\n",
      "\n",
      "When Amelia came in, she immediately bought two croissants which were made using a baking tool.\n",
      "\n",
      "Note: I removed \"in the oven\" as it was inconsistent with the fact that baking requires a tool. The rest of the original content remains unchanged.\n",
      "\n",
      "=== FINAL OUTPUT ===\n",
      "Here is the rewritten chunk:\n",
      "\n",
      "It was the day when Paris had no electricity.\n",
      "\n",
      "Note: The original sentence mentioned \"there was no electricity in Paris\", but since we only have a fact about Paris having NoElectricity, we simplified the sentence to reflect this. Amelia went to the bakery where Adam worked. Here is the rewritten story chunk based on the provided triples:\n",
      "\n",
      "When Amelia came in, she immediately bought two croissants which were made using a baking tool.\n",
      "\n",
      "Note: I removed \"in the oven\" as it was inconsistent with the fact that baking requires a tool. The rest of the original content remains unchanged.\n",
      "\n",
      "\n",
      "#############################\n",
      "### RUNNING SCENARIO 7 ###\n",
      "#############################\n",
      "Los Angeles has a high population and is a quiet and empty city\n",
      "\n",
      "\n",
      "=== Node: Chunk ===\n",
      "['Los Angeles has a high population and is a quiet and empty city']\n",
      "\n",
      "=== Node: Extract Triples ===\n",
      "chunk_0 -> [{'subj': 'Los_Angeles', 'pred': 'description', 'obj': 'quiet'}, {'subj': 'and', 'pred': 'description', 'obj': 'empty'}, {'subj': 'Los_Angeles', 'pred': 'hasPopulation', 'obj': 'high'}]\n",
      "\n",
      "=== Node: Check Conflicts with SPARQL ===\n",
      "chunk_0 conflicts -> [{'subj': 'Los_Angeles', 'pred': 'description', 'obj': 'quiet'}]\n",
      "\n",
      "=== METRICS — BEFORE REWRITE ===\n",
      "{'tp': 1, 'tn': 1, 'fp': 0, 'fn': 1, 'precision': 1.0, 'recall': 0.5, 'f1': 0.6666666666666666, 'accuracy': 0.6666666666666666}\n",
      "Gold violations (sum of y_true): 2\n",
      "\n",
      "=== REPUTATION — BEFORE ===\n",
      "Overall: 0.333\n",
      "  Worst chunks (↓): chunk_0:0.33\n",
      "  Best  chunks (↑): chunk_0:0.33\n",
      "  Worst subjects (↓): los_angeles:0.00, <empty>:1.00\n",
      "  Best  subjects (↑): <empty>:1.00, los_angeles:0.00\n",
      "\n",
      "=== Node: Rewrite Conflicts ===\n",
      "chunk_0: Here is the rewritten chunk based on the provided triples:\n",
      "\n",
      "Los Angeles has a high population and is a bustling city\n",
      "\n",
      "=== Node: Re-verify ===\n",
      "\n",
      "=== Node: Extract Triples ===\n",
      "chunk_0 -> [{'subj': 'Los_Angeles', 'pred': 'hasPopulation', 'obj': 'high'}]\n",
      "\n",
      "=== Node: Check Conflicts with SPARQL ===\n",
      "chunk_0 conflicts -> []\n",
      "\n",
      "=== Node: Extract Triples ===\n",
      "chunk_0 -> [{'subj': 'Los_Angeles', 'pred': 'hasPopulation', 'obj': 'high'}]\n",
      "\n",
      "=== Node: Check Conflicts with SPARQL ===\n",
      "chunk_0 conflicts -> []\n",
      "\n",
      "=== METRICS — AFTER REWRITE ===\n",
      "{'tp': 0, 'tn': 1, 'fp': 0, 'fn': 0, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'accuracy': 1.0}\n",
      "Gold violations (sum of y_true): 0\n",
      "\n",
      "=== REPUTATION — AFTER ===\n",
      "Overall: 1.000\n",
      "  Worst chunks (↓): chunk_0:1.00\n",
      "  Best  chunks (↑): chunk_0:1.00\n",
      "  Worst subjects (↓): los_angeles:1.00\n",
      "  Best  subjects (↑): los_angeles:1.00\n",
      "\n",
      "=== SUMMARY ===\n",
      "Resolution: 1.000  (gold violations 2 → 0)\n",
      "\n",
      "=== Node: Final Story ===\n",
      "Here is the rewritten chunk based on the provided triples:\n",
      "\n",
      "Los Angeles has a high population and is a bustling city\n",
      "\n",
      "=== FINAL OUTPUT ===\n",
      "Here is the rewritten chunk based on the provided triples:\n",
      "\n",
      "Los Angeles has a high population and is a bustling city\n",
      "\n",
      "\n",
      "#############################\n",
      "### RUNNING SCENARIO 8 ###\n",
      "#############################\n",
      "Jan is 115 years old.\n",
      "\n",
      "\n",
      "=== Node: Chunk ===\n",
      "['Jan is 115 years old.']\n",
      "\n",
      "=== Node: Extract Triples ===\n",
      "chunk_0 -> [{'subj': 'Jan', 'pred': 'hasAge', 'obj': '115'}]\n",
      "\n",
      "=== Node: Check Conflicts with SPARQL ===\n",
      "chunk_0 conflicts -> []\n",
      "\n",
      "=== METRICS — BEFORE REWRITE ===\n",
      "{'tp': 0, 'tn': 1, 'fp': 0, 'fn': 0, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'accuracy': 1.0}\n",
      "Gold violations (sum of y_true): 0\n",
      "\n",
      "=== REPUTATION — BEFORE ===\n",
      "Overall: 1.000\n",
      "  Worst chunks (↓): chunk_0:1.00\n",
      "  Best  chunks (↑): chunk_0:1.00\n",
      "  Worst subjects (↓): jan:1.00\n",
      "  Best  subjects (↑): jan:1.00\n",
      "\n",
      "=== Node: Rewrite Conflicts ===\n",
      "chunk_0: Jan is 115 years old.\n",
      "\n",
      "=== Node: Re-verify ===\n",
      "\n",
      "=== Node: Extract Triples ===\n",
      "chunk_0 -> [{'subj': 'Jan', 'pred': 'hasAge', 'obj': '115'}]\n",
      "\n",
      "=== Node: Check Conflicts with SPARQL ===\n",
      "chunk_0 conflicts -> []\n",
      "\n",
      "=== Node: Extract Triples ===\n",
      "chunk_0 -> [{'subj': 'Jan', 'pred': 'hasAge', 'obj': '115'}]\n",
      "\n",
      "=== Node: Check Conflicts with SPARQL ===\n",
      "chunk_0 conflicts -> []\n",
      "\n",
      "=== METRICS — AFTER REWRITE ===\n",
      "{'tp': 0, 'tn': 1, 'fp': 0, 'fn': 0, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'accuracy': 1.0}\n",
      "Gold violations (sum of y_true): 0\n",
      "\n",
      "=== REPUTATION — AFTER ===\n",
      "Overall: 1.000\n",
      "  Worst chunks (↓): chunk_0:1.00\n",
      "  Best  chunks (↑): chunk_0:1.00\n",
      "  Worst subjects (↓): jan:1.00\n",
      "  Best  subjects (↑): jan:1.00\n",
      "\n",
      "=== SUMMARY ===\n",
      "Resolution: 0.000  (gold violations 0 → 0)\n",
      "\n",
      "=== Node: Final Story ===\n",
      "Jan is 115 years old.\n",
      "\n",
      "=== FINAL OUTPUT ===\n",
      "Jan is 115 years old.\n",
      "\n",
      "\n",
      "#############################\n",
      "### RUNNING SCENARIO 9 ###\n",
      "#############################\n",
      "Jan is reserved. During lunch Jan enjoys conversations with other patients, nurses, and all the other staff.\n",
      "\n",
      "\n",
      "=== Node: Chunk ===\n",
      "['Jan is reserved.', 'During lunch Jan enjoys conversations with other patients, nurses, and all the other staff.']\n",
      "\n",
      "=== Node: Extract Triples ===\n",
      "chunk_0 -> [{'subj': 'Jan', 'pred': 'hasTrait', 'obj': 'Reserved'}]\n",
      "chunk_1 -> []\n",
      "\n",
      "=== Node: Check Conflicts with SPARQL ===\n",
      "chunk_0 conflicts -> [{'subj': 'Jan', 'pred': 'hasTrait', 'obj': 'Reserved'}]\n",
      "chunk_1 conflicts -> []\n",
      "\n",
      "=== METRICS — BEFORE REWRITE ===\n",
      "{'tp': 0, 'tn': 0, 'fp': 1, 'fn': 0, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'accuracy': 0.0}\n",
      "Gold violations (sum of y_true): 0\n",
      "\n",
      "=== REPUTATION — BEFORE ===\n",
      "Overall: 1.000\n",
      "  Worst chunks (↓): chunk_0:1.00\n",
      "  Best  chunks (↑): chunk_0:1.00\n",
      "  Worst subjects (↓): jan:1.00\n",
      "  Best  subjects (↑): jan:1.00\n",
      "\n",
      "=== Node: Rewrite Conflicts ===\n",
      "chunk_0: I'm ready to fix those inconsistencies!\n",
      "\n",
      "Story chunk after editing:\n",
      "Jan hasTrait Reserved\n",
      "chunk_1: During lunch Jan enjoys conversations with other patients, nurses, and all the other staff.\n",
      "\n",
      "=== Node: Re-verify ===\n",
      "\n",
      "=== Node: Extract Triples ===\n",
      "chunk_0 -> []\n",
      "chunk_1 -> []\n",
      "\n",
      "=== Node: Check Conflicts with SPARQL ===\n",
      "chunk_0 conflicts -> []\n",
      "chunk_1 conflicts -> []\n",
      "\n",
      "=== Node: Extract Triples ===\n",
      "chunk_0 -> []\n",
      "chunk_1 -> []\n",
      "\n",
      "=== Node: Check Conflicts with SPARQL ===\n",
      "chunk_0 conflicts -> []\n",
      "chunk_1 conflicts -> []\n",
      "\n",
      "=== METRICS — AFTER REWRITE ===\n",
      "{'tp': 0, 'tn': 0, 'fp': 0, 'fn': 0, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'accuracy': 0.0}\n",
      "Gold violations (sum of y_true): 0\n",
      "\n",
      "=== REPUTATION — AFTER ===\n",
      "Overall: 1.000\n",
      "  (no chunk-level records)\n",
      "  (no subject-level records)\n",
      "\n",
      "=== SUMMARY ===\n",
      "Resolution: 0.000  (gold violations 0 → 0)\n",
      "\n",
      "=== Node: Final Story ===\n",
      "I'm ready to fix those inconsistencies!\n",
      "\n",
      "Story chunk after editing:\n",
      "Jan hasTrait Reserved During lunch Jan enjoys conversations with other patients, nurses, and all the other staff.\n",
      "\n",
      "=== FINAL OUTPUT ===\n",
      "I'm ready to fix those inconsistencies!\n",
      "\n",
      "Story chunk after editing:\n",
      "Jan hasTrait Reserved During lunch Jan enjoys conversations with other patients, nurses, and all the other staff.\n",
      "\n",
      "\n",
      "================== OVERALL (ALL RUNS) ==================\n",
      "Micro BEFORE: {'tp': 5, 'tn': 5, 'fp': 2, 'fn': 1, 'precision': 0.7142857142857143, 'recall': 0.8333333333333334, 'f1': 0.7692307692307692, 'accuracy': 0.7692307692307693}\n",
      "Micro AFTER : {'tp': 0, 'tn': 7, 'fp': 1, 'fn': 0, 'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'accuracy': 0.875}\n",
      "Total gold violations: 6 → 0  (Resolution: 1.000)\n",
      "========================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================== Main / Scenarios ==============================\n",
    "if __name__ == \"__main__\":\n",
    "    scenarios = {\n",
    "        1: \"\"\"Amelia is one of France's most famous lawyers. She is 17 years old and recently married her husband Adam, who is 25.\"\"\",\n",
    "        2: \"\"\"They live together in Paris, a quiet city without much hustle and bustle since the city has a large population.\n",
    "The city is located on flat land, so there are no mountains.\"\"\",\n",
    "        3: \"\"\"The Eiffel Tower is located in Italy.\"\"\",\n",
    "        4: \"\"\"Her husband Adam is a baker and a merchant. He makes various types of French pastries, including macarons, but also baguettes and croissants.\n",
    "Unfortunately, Amelia cannot eat many sweets because she is allergic to the filling which contains dairy.\"\"\",\n",
    "        5: \"\"\"Amelia's husband describes her as a good hearted and self serving person who cares about the well-being of people.\"\"\",\n",
    "        6: \"\"\"It was the day that there was no electricity in Paris. Amelia went to the bakery where Adam worked.\n",
    "When Amelia came in, she immediately bought two croissants which were made in the oven.\"\"\",\n",
    "        7: \"\"\"Los Angeles has a high population and is a quiet and empty city\"\"\",\n",
    "        8: \"\"\"Jan is 115 years old.\"\"\",\n",
    "        9: \"\"\"Jan is reserved. During lunch Jan enjoys conversations with other patients, nurses, and all the other staff.\"\"\"\n",
    "    }\n",
    "\n",
    "    import argparse, sys\n",
    "    ap = argparse.ArgumentParser(description=\"Run full story pipeline on scenarios or custom text.\")\n",
    "    ap.add_argument(\"--scenario\", type=int, default=None, help=\"Scenario number (1-9). Ignored if --story or --all.\")\n",
    "    ap.add_argument(\"--story\", type=str, default=None, help=\"Custom story text to process (single run).\")\n",
    "    ap.add_argument(\"--all\", action=\"store_true\", help=\"Run ALL predefined scenarios (1-9).\")\n",
    "    args, _unknown = ap.parse_known_args()\n",
    "\n",
    "    def run_full_once(story_text: str, label: str):\n",
    "        print(f\"\\n\\n#############################\")\n",
    "        print(f\"### RUNNING {label.upper()} ###\")\n",
    "        print(f\"#############################\\n{story_text}\\n\")\n",
    "\n",
    "        # --- BEFORE ---\n",
    "        state = chunk({\"story\": story_text})\n",
    "        state = extract(state)\n",
    "        state = check_conflicts(state)\n",
    "\n",
    "        y_true_b, y_pred_b, aligned_b = collect_labels(state)\n",
    "        mb = compute_metrics(y_true_b, y_pred_b)\n",
    "        vb = sum(y_true_b)\n",
    "\n",
    "        print(\"\\n=== METRICS — BEFORE REWRITE ===\")\n",
    "        print(mb)\n",
    "        print(f\"Gold violations (sum of y_true): {vb}\")\n",
    "\n",
    "        rep_b = reputation_scores(aligned_b, y_true_b)\n",
    "        _print_reputation(\"BEFORE\", rep_b, top_k=5)\n",
    "\n",
    "        # --- REWRITE + RE-VERIFY ---\n",
    "        state = rewrite_conflicts(state)\n",
    "        state = reverify_chunks(state)\n",
    "\n",
    "        ex_after, conf_after = recompute_on_text(state.get(\"re_verified_chunks\", []))\n",
    "        temp_after: InbetweenState = {\n",
    "            \"story\": \" \".join(state.get(\"re_verified_chunks\", [])),\n",
    "            \"chunks\": state.get(\"re_verified_chunks\", []),\n",
    "            \"ontology_summary\": \"\",\n",
    "            \"extract\": ex_after,\n",
    "            \"conflicts\": conf_after,\n",
    "            \"rewritten_chunks\": [],\n",
    "            \"re_verified_chunks\": [],\n",
    "            \"evaluated_chunks\": []\n",
    "        }\n",
    "\n",
    "        # --- AFTER ---\n",
    "        y_true_a, y_pred_a, aligned_a = collect_labels(temp_after)\n",
    "        ma = compute_metrics(y_true_a, y_pred_a)\n",
    "        va = sum(y_true_a)\n",
    "\n",
    "        print(\"\\n=== METRICS — AFTER REWRITE ===\")\n",
    "        print(ma)\n",
    "        print(f\"Gold violations (sum of y_true): {va}\")\n",
    "\n",
    "        rep_a = reputation_scores(aligned_a, y_true_a)\n",
    "        _print_reputation(\"AFTER\", rep_a, top_k=5)\n",
    "\n",
    "        resolution = ((vb - va) / vb) if vb else 0.0\n",
    "        print(\"\\n=== SUMMARY ===\")\n",
    "        print(f\"Resolution: {resolution:.3f}  (gold violations {vb} → {va})\")\n",
    "\n",
    "        # --- Final story ---\n",
    "        try:\n",
    "            final_state = assemble_final_story(state)\n",
    "            revised = final_state.get(\"revised_story\", \"\")\n",
    "        except NameError:\n",
    "            revised = \" \".join(state.get(\"re_verified_chunks\") or state.get(\"rewritten_chunks\") or state.get(\"chunks\") or [])\n",
    "\n",
    "        print(\"\\n=== FINAL OUTPUT ===\")\n",
    "        print(revised if revised else \"[main] No revised story produced.\")\n",
    "\n",
    "        # Return for micro-averaging\n",
    "        return {\n",
    "            \"before\": mb,\n",
    "            \"after\": ma,\n",
    "            \"viol_before\": vb,\n",
    "            \"viol_after\": va\n",
    "        }\n",
    "\n",
    "    # Decide run mode\n",
    "    runs_meta = []\n",
    "    if args.story and args.story.strip():\n",
    "        runs_meta.append(run_full_once(args.story.strip(), \"custom\"))\n",
    "    elif args.all or args.scenario is None:\n",
    "        # Default to ALL if no specific scenario or custom story is provided\n",
    "        for k in sorted(scenarios.keys()):\n",
    "            runs_meta.append(run_full_once(scenarios[k], f\"scenario {k}\"))\n",
    "    else:\n",
    "        if args.scenario not in scenarios:\n",
    "            print(f\"[main] Scenario {args.scenario} not found. Choose 1–9, pass --all, or use --story.\")\n",
    "            sys.exit(2)\n",
    "        runs_meta.append(run_full_once(scenarios[args.scenario], f\"scenario {args.scenario}\"))\n",
    "\n",
    "    # === MICRO-AVERAGED OVER ALL RUNS ===\n",
    "    micro_before = micro_sum([r[\"before\"] for r in runs_meta])\n",
    "    micro_after  = micro_sum([r[\"after\"]  for r in runs_meta])\n",
    "    vb_total = sum(int(r[\"viol_before\"]) for r in runs_meta)\n",
    "    va_total = sum(int(r[\"viol_after\"])  for r in runs_meta)\n",
    "    resolution_total = ((vb_total - va_total) / vb_total) if vb_total else 0.0\n",
    "\n",
    "    print(\"\\n\\n================== OVERALL (ALL RUNS) ==================\")\n",
    "    print(\"Micro BEFORE:\", micro_before)\n",
    "    print(\"Micro AFTER :\", micro_after)\n",
    "    print(f\"Total gold violations: {vb_total} → {va_total}  (Resolution: {resolution_total:.3f})\")\n",
    "    print(\"========================================================\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b889af-2eec-4cb3-8fbe-d901d01d9b46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
